[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/new-new-test-post/index.html",
    "href": "posts/new-new-test-post/index.html",
    "title": "Timnit Gebru",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-new-test-post/index.html#math",
    "href": "posts/new-new-test-post/index.html#math",
    "title": "Timnit Gebru",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "from source import Perceptron\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "This is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "Bias Replication Study\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/bias-replication-post/Bias-Replication.html",
    "href": "posts/bias-replication-post/Bias-Replication.html",
    "title": "Bias Replication Study",
    "section": "",
    "text": "This data frame represents disparities in medical data, including medical cost, risk score, and number of chronic illnesses, between Black and white patients. The plots shown are visual representations of such disparities, replicating studies by Obermeyer et al. in 2019 article “Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations.” These plots show clear distinctions between the costs incurred by Black and white patients and the likelihood of being referred to a high-risk medical program for a given number of illnesses. The linear regression I performed displays logarithmic coefficient w_b, which, when presented as \\(e^(w_b)\\), represents the percentage of a white patient’s cost that a Black patient must pay. My calculation revealed that a Black patient pays over 100% of what a white patient pays for the same illness(es), supporting the idea that racial disparities are prevalent in healthcare.\n\nimport pandas as pd\nurl = \"https://gitlab.com/labsysmed/dissecting-bias/-/raw/master/data/data_new.csv?inline=false\"\ndf = pd.read_csv(url)\ndf\n\n\n\n\n\n\n\n\nrisk_score_t\nprogram_enrolled_t\ncost_t\ncost_avoidable_t\nbps_mean_t\nghba1c_mean_t\nhct_mean_t\ncre_mean_t\nldl_mean_t\nrace\n...\ntrig_min-high_tm1\ntrig_min-normal_tm1\ntrig_mean-low_tm1\ntrig_mean-high_tm1\ntrig_mean-normal_tm1\ntrig_max-low_tm1\ntrig_max-high_tm1\ntrig_max-normal_tm1\ngagne_sum_tm1\ngagne_sum_t\n\n\n\n\n0\n1.987430\n0\n1200.0\n0.0\nNaN\n5.4\nNaN\n1.110000\n194.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n7.677934\n0\n2600.0\n0.0\n119.0\n5.5\n40.4\n0.860000\n93.0\nwhite\n...\n0\n1\n0\n0\n1\n0\n0\n1\n4\n3\n\n\n2\n0.407678\n0\n500.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0.798369\n0\n1300.0\n0.0\n117.0\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n17.513165\n0\n1100.0\n0.0\n116.0\nNaN\n34.1\n1.303333\n53.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n48779\n0.611517\n0\n800.0\n0.0\nNaN\nNaN\nNaN\n1.090000\n148.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n48780\n2.615933\n0\n2200.0\n0.0\n112.0\nNaN\n41.4\n0.810000\n172.0\nwhite\n...\n0\n1\n0\n0\n1\n0\n0\n1\n1\n1\n\n\n48781\n1.358926\n0\n800.0\n0.0\n105.0\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n1\n0\n0\n1\n0\n0\n1\n1\n0\n\n\n48782\n10.990318\n0\n1300.0\n0.0\n132.0\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n3\n3\n\n\n48783\n1.681671\n0\n4400.0\n0.0\n115.0\n5.6\n36.6\n0.940000\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n48784 rows × 160 columns\n\n\n\n\n\n\nIn this figure we plot risk score percentile by the mean number of chronic illnesses within each percentile, with data points separated by race. Here we see a clear difference between races, with white patients more likely to be given a higher risk score than Black patients with the same number of chronic illnesses. If Patient A were white and Patient B were Black, and both patients had the same chronic illnesses, Patient A would be significantly more likely to have a higher risk score and be referred to a high-risk care management program.\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Calculate risk score percentiles\ndf['risk_score_percentile'] = df['risk_score_t'].rank(pct=True).round(2)\n\n\n# Calculate mean number of gagne_sum_t within each risk score percentile\nmean_gagne_per_percentile = df.groupby(['risk_score_percentile', 'race'])['gagne_sum_t'].mean().reset_index()\n\n\n# Plot\nsns.scatterplot(data=mean_gagne_per_percentile, x='gagne_sum_t', y='risk_score_percentile', hue='race', style='race')\nplt.xlabel('Mean Chronic Illnesses')\nplt.ylabel('Risk Score Percentile')\nplt.xlim(0,8)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nHere we explore differences in cost incurred by Black and white patients with various risk scores and various numbers of chronic illnesses. These figures suggest that, for Black patients, as risk score and number of chronic illnesses increase, medical expenditures increase at a higher rate than that of white patients. For lower risk scores and chronic illness counts, white patients seem to have slightly higher medical costs than for Black patients, but it appears as though Black patients are penalized more severely for having more illnesses and being of higher risk.\n\n#group data with risk score percentile and cost\ndf_cost = df.groupby(['risk_score_percentile', 'race'])['cost_t'].mean().reset_index()\n\n#group data with number of chronic illnesses and cost\ndf_cost2 = df.groupby(['gagne_sum_t', 'race'])['cost_t'].mean().reset_index()\n\n\nfig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 5))\n\n#plot cost by percentile risk score\np1 = sns.scatterplot(data=df_cost, x='risk_score_percentile', y='cost_t', hue='race', style='race', ax = ax1)\np1.set_xlabel('Percentile Risk Score')\np1.set_ylabel('Total Medical Expenditures')\nplt.gca().semilogy()\n\n#plot cost by number of chronic illnesses\np2 = sns.scatterplot(data=df_cost2, x='gagne_sum_t', y='cost_t', hue='race', style='race', ax = ax2)\np2.set_xlabel('Number of Chronic Illnesses')\np2.set_ylabel('Total Medical Expenditures')\nplt.gca().semilogy()\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\n\n# Calculate the percentage of patients with 5 or fewer chronic conditions\npercentage = (len(df[df['gagne_sum_t'] &lt;= 5]) / len(df)) * 100\n\n# 95.53952115447689 - choice to use patients with 5 or fewer chronic conditions makes sense, \n# as 96% of patients have 5 or fewer chronic conditions.\n\n# Eliminate subjects with 0 cost, perform log function on cost column\ndf = df[df['cost_t'] &gt; 0]\ndf['log_cost'] = df['cost_t'].apply(lambda x: np.log(x))\n\n# Create a dummy column for the race variable\ndf['race_encoded'] = pd.get_dummies(df['race'], drop_first=True)\n\n# Separate the data into predictor variables (X) and target variable (y)\nX = df[['race_encoded', 'gagne_sum_t']]\ny = df['log_cost']\n\n\n\n\n\n\n\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Function to add polynomial features\ndef add_polynomial_features(X, degree):\n    X_ = X.copy()\n    for j in range(1, degree):\n        X_[f\"poly_{j}\"] = X_[\"gagne_sum_t\"]**j\n    return X_\n\n# Create different degrees of polynomial features and compute cross-validation scores\ndegrees = range(1, 15)\nscores = []\n\nfor degree in degrees:\n    # Add polynomial features\n    X_poly = add_polynomial_features(X, degree)\n    \n    # Perform cross-validation with linear regression\n    lr = LinearRegression()\n    cv_score = cross_val_score(lr, X_poly, y, cv=5).mean()\n    scores.append(cv_score)\n\n# Determine the optimal degree based on cross-validation scores\noptimal_degree = degrees[np.argmax(scores)]\nprint(\"Optimal degree based on cross-validation:\", optimal_degree)\n\n# Construct data with the optimal number of polynomial features\nX_poly_optimal = add_polynomial_features(X, optimal_degree)\n\n# Fit the final linear regression model\nlr_final = LinearRegression()\nlr_final.fit(X_poly_optimal, y)\n\n# Get coefficients of the linear regression model\ncoefficients = lr_final.coef_\n\n\n# Identify the coefficient corresponding to the Black race\nwb = coefficients[-1]\nprint(\"w_b: \", wb)\n\n# Compute e^wb\ne_wb = np.exp(wb)\nprint(\"e^w_b: \", e_wb)\n\nOptimal degree based on cross-validation: 10\nw_b:  9.390071033164823e-08\ne^w_b:  1.0000000939007148\n\n\nThis linear regression model worked best with cross validation on 10 polynomial degrees. After fitting the final linear regression model, the value I received for e^(w_b) was 1.0000000939007148, indicating that a Black patient pays slightly over 100% of the cost that an equally sick white patient must pay.\n\n\n\nThe above plots give visual representations of racial disparities in medical care, and the logistic regression models slight disparities in cost incurred by equally sick patients. However, while this value of slightly more than 100% may seem like only a minor difference, it could be suggested that the value extracted from the regression does not account for the kinds of disparities that are present. As we see in the Medical Expenditure Plots above, as Risk Score Percentile and Number of Chronic Illnesses increase, so does the different in cost between Black and white patients. While white patients might pay as much as or more than Black patients for lower-risk, less severe conditions, Black patients are financially penalized as their conditions become more severe, and the logistic regression does not account for this idea. The plots clearly model differences in the way Black and white patients are treated, specifically of Barocas et al’s discrimination criterion of “outcome frequency given score value”. If these observations were “fair”, statistics for Black and white patients would be about equal, given that their medical conditions are identical. However, we do see clear outliers and differing trends between patients of different race but identical medical conditions, scoring Black patients at significantly lower risk than equally sick white patients and with high-risk Black patients incurring significantly higher medical costs than equally sick white patients."
  },
  {
    "objectID": "posts/bias-replication-post/Bias-Replication.html#abstract",
    "href": "posts/bias-replication-post/Bias-Replication.html#abstract",
    "title": "Bias Replication Study",
    "section": "",
    "text": "This data frame represents disparities in medical data, including medical cost, risk score, and number of chronic illnesses, between Black and white patients. The plots shown are visual representations of such disparities, replicating studies by Obermeyer et al. in 2019 article “Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations.” These plots show clear distinctions between the costs incurred by Black and white patients and the likelihood of being referred to a high-risk medical program for a given number of illnesses. The linear regression I performed displays logarithmic coefficient w_b, which, when presented as \\(e^(w_b)\\), represents the percentage of a white patient’s cost that a Black patient must pay. My calculation revealed that a Black patient pays over 100% of what a white patient pays for the same illness(es), supporting the idea that racial disparities are prevalent in healthcare.\n\nimport pandas as pd\nurl = \"https://gitlab.com/labsysmed/dissecting-bias/-/raw/master/data/data_new.csv?inline=false\"\ndf = pd.read_csv(url)\ndf\n\n\n\n\n\n\n\n\nrisk_score_t\nprogram_enrolled_t\ncost_t\ncost_avoidable_t\nbps_mean_t\nghba1c_mean_t\nhct_mean_t\ncre_mean_t\nldl_mean_t\nrace\n...\ntrig_min-high_tm1\ntrig_min-normal_tm1\ntrig_mean-low_tm1\ntrig_mean-high_tm1\ntrig_mean-normal_tm1\ntrig_max-low_tm1\ntrig_max-high_tm1\ntrig_max-normal_tm1\ngagne_sum_tm1\ngagne_sum_t\n\n\n\n\n0\n1.987430\n0\n1200.0\n0.0\nNaN\n5.4\nNaN\n1.110000\n194.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n7.677934\n0\n2600.0\n0.0\n119.0\n5.5\n40.4\n0.860000\n93.0\nwhite\n...\n0\n1\n0\n0\n1\n0\n0\n1\n4\n3\n\n\n2\n0.407678\n0\n500.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0.798369\n0\n1300.0\n0.0\n117.0\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n17.513165\n0\n1100.0\n0.0\n116.0\nNaN\n34.1\n1.303333\n53.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n48779\n0.611517\n0\n800.0\n0.0\nNaN\nNaN\nNaN\n1.090000\n148.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n48780\n2.615933\n0\n2200.0\n0.0\n112.0\nNaN\n41.4\n0.810000\n172.0\nwhite\n...\n0\n1\n0\n0\n1\n0\n0\n1\n1\n1\n\n\n48781\n1.358926\n0\n800.0\n0.0\n105.0\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n1\n0\n0\n1\n0\n0\n1\n1\n0\n\n\n48782\n10.990318\n0\n1300.0\n0.0\n132.0\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n3\n3\n\n\n48783\n1.681671\n0\n4400.0\n0.0\n115.0\n5.6\n36.6\n0.940000\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n48784 rows × 160 columns"
  },
  {
    "objectID": "Optimal-Decision-Making.html",
    "href": "Optimal-Decision-Making.html",
    "title": "Intro: Optimal Decision Making",
    "section": "",
    "text": "Intro: Optimal Decision Making\nFairness - it does not seem fair that people who are most in need of loans are least likely to receive them.\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import validation\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf = pd.read_csv(url)\ndf = df.dropna()\ndf\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_home_ownership\nperson_emp_length\nloan_intent\nloan_grade\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_default_on_file\ncb_person_cred_hist_length\n\n\n\n\n1\n27\n98000\nRENT\n3.0\nEDUCATION\nC\n11750\n13.47\n0\n0.12\nY\n6\n\n\n2\n22\n36996\nRENT\n5.0\nEDUCATION\nA\n10000\n7.51\n0\n0.27\nN\n4\n\n\n3\n24\n26000\nRENT\n2.0\nMEDICAL\nC\n1325\n12.87\n1\n0.05\nN\n4\n\n\n4\n29\n53004\nMORTGAGE\n2.0\nHOMEIMPROVEMENT\nA\n15000\n9.63\n0\n0.28\nN\n10\n\n\n6\n21\n21700\nRENT\n2.0\nHOMEIMPROVEMENT\nD\n5500\n14.91\n1\n0.25\nN\n2\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n26059\n36\n150000\nMORTGAGE\n8.0\nEDUCATION\nA\n3000\n7.29\n0\n0.02\nN\n17\n\n\n26060\n23\n48000\nRENT\n1.0\nVENTURE\nA\n4325\n5.42\n0\n0.09\nN\n4\n\n\n26061\n22\n60000\nRENT\n0.0\nMEDICAL\nB\n15000\n11.71\n0\n0.25\nN\n4\n\n\n26062\n30\n144000\nMORTGAGE\n12.0\nPERSONAL\nC\n35000\n12.68\n0\n0.24\nN\n8\n\n\n26063\n25\n60000\nRENT\n5.0\nEDUCATION\nA\n21450\n7.29\n1\n0.36\nN\n4\n\n\n\n\n22907 rows × 12 columns\n\n\n\n\nBoxplot of Person Age by Loan Intent\nThis plot shows the concentration of ages for which each loan intent is most prevalent. As most loan recipients are young adults, between around 20 and 35, there isn’t a significant amount of variation between the categories, though there are some notable disparities. Education has a quite narrow concentration of ages and is focused between the ages of around 24 to 29, whereas Home Improvement loans are taken out mostly by 26 to 32-year-olds with plenty of outliers of older ages. This seems to make sense, as newer adults may not have the time or resources to focus on improving their homes as much as older, more mature adults might. People of a broad range of ages take out loans for Venture, Personal, and Debt Consolidation purposes, and Medical loans are taken out mostly by people in their late 20s and early 30s, again with outliers extending into much older ages.\n\ndf_age = df[[\"person_age\", \"loan_intent\"]]\n\nplt.figure(figsize=(10, 6))\nsns.boxplot(x='loan_intent', y='person_age', data=df_age)\nplt.xlabel('Loan Intent')\nplt.ylabel('Person Age')\nplt.title('Box Plot of Person Age by Loan Intent')\nplt.ylim(20, 60)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nScatter Plot of Loan Interest Rate by Person Age\nThis is quite a dense scatterplot, as there are very many subjects in this dataset, but it still allows us to see a pattern. Maximum loan interest rates seem to be highest around 24 years of age and steadily decrease as the loan recipient grows older. Specifically, around 50 years of age, loan interest rates peak around 16%, whereas the peak interest rate for 24-year-olds is 22%. This could be because younger people are more likely to fault on loans, as they may have less financial stability than older adults.\n\ndf_income = df[[\"person_age\", \"loan_int_rate\"]]\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x='person_age', y='loan_int_rate', data=df_income)\nplt.xlabel('Person Age')\nplt.ylabel('Loan Interest Rate')\nplt.title('Scatter Plot of Loan Interest Rate by Person Age')\nplt.xlim(20,60)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nFitting a Score Function\nI am choosing to examine how Person Income and Loan Percent Income contribute to Loan Status. I am using SciKitLearn’s Logistic Regression model to assign scores to my two x variables.\n\n#fit logistic regression model\ndf_train, df_test = train_test_split(df, test_size = 0.2, random_state = 123) # 20% test set\n\nX_train = df_train[[\"person_emp_length\", \"loan_int_rate\"]]\ny_train = df_train[[\"loan_status\"]].values.ravel()\n\nX_test = df_test[[\"person_emp_length\", \"loan_int_rate\"]]\ny_test = df_test[[\"loan_status\"]]\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# get model coefficients\ncoefficients = model.coef_\n\ndef linear_score(X, w):\n    return X@w\n\nw = model.coef_.squeeze()\ns = linear_score(X_train, w)\nw\n\narray([-0.04924616,  0.28220565])\n\n\n\nhist = plt.hist(s)\nlabs = plt.gca().set(xlabel = r\"Score $s$\", ylabel = \"Frequency\") \n\n\n\n\n\n\n\n\n\n# calculate profit for each loan\ndef calculate_expected_profit(scores, loan_amnts, loan_int_rates, t):\n    \n   # profit_default = loan_amnts*(1 + 0.25 * loan_int_rates)**3 - 1.7*loan_amnts\n    #profit_repaid = loan_amnts*(1 + 0.25 * loan_int_rates)**10 - loan_amnts\n    \n    \n    expected_profits = []\n    for s, a, i in zip(scores, loan_amnts, loan_int_rates):\n        #profit for expected repayment\n        if s &gt;= t:\n            expected_profits.append(a*(1 + 0.25 * i)**10 - a)\n        #profit for expected default\n        else:\n            expected_profits.append(a*(1 + 0.25 * i)**3 - 1.7*a)\n    \n    return np.array(expected_profits)\n\n# Evaluate expected profit for different thresholds\ndef choose_threshold(scores, loan_amnts, loan_int_rates):\n    # Initialize variables to track threshold and maximum profit\n    max_profit = float('-inf')\n    best_threshold = None\n    \n    # Iterate over possible thresholds\n    for threshold in scores:\n        # Calculate profit for each instance using the current threshold\n        profits = calculate_expected_profit(scores, loan_amnts, loan_int_rates, threshold)\n        \n        # Calculate total profit\n        total_profit = profits.sum()\n        \n        # Update best threshold if total profit is higher\n        if total_profit &gt; max_profit:\n            max_profit = total_profit\n            best_threshold = threshold\n    \n    return best_threshold\n\n\n\n\n# Choose threshold\nloan_amnts = df_train[[\"loan_amnt\"]].squeeze()\nloan_int_rates = df_train[[\"loan_int_rate\"]].squeeze()\nbest_threshold = choose_threshold(s, loan_amnts, loan_int_rates)\nprint(\"Best threshold:\", best_threshold)\n\nBest threshold: -4.21165258842873\n\n\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/test.csv\"\ndf_test = pd.read_csv(url)\n\n\ndf_test_X = df_test[[\"person_emp_length\", \"loan_int_rate\"]]\ntest_amnts = df_test[[\"loan_amnt\"]].squeeze()\ntest_rates = df_test[[\"loan_int_rate\"]].squeeze()\ntest_scores = linear_score(df_test_X, w)\ntest_profits = calculate_expected_profit(test_scores, test_amnts, test_rates, best_threshold)\ntest_profits\n\narray([8.51905969e+08, 1.42483647e+11, 6.40822286e+08, ...,\n       7.91880603e+09, 4.57162163e+10, 6.06741469e+09])\n\n\n\n# Add predicted probabilities to the test data\nX_test['predicted_probabilities'] = model.predict_proba(X_test)[:, 1]\n\n# 1. Is it more difficult for people in certain age groups to access credit?\n# Group by age groups and calculate the average predicted probability of default\nage_groups_probabilities = X_test.groupby(pd.cut(X_test['person_age'], bins=[20, 30, 40, 50, 60, 70, 80]))['predicted_probabilities'].mean()\n\n# 2. Is it more difficult for people to get loans for specific purposes?\n# Group by loan_intent and calculate the average predicted probability of default\nloan_intent_probabilities = X_test.groupby('loan_intent')['predicted_probabilities'].mean()\n\n# 3. How does a person's income level impact the ease of accessing credit?\n# Group by income levels and calculate the average predicted probability of default\nincome_levels_probabilities = X_test.groupby(pd.cut(X_test['person_income'], bins=[0, 50000, 100000, 150000, 200000, float('inf')]))['predicted_probabilities'].mean()\n\n# Compare with the actual default rate in each group\nactual_default_rate = y_test.mean()\n\n# Print the results\nprint(\"Average predicted probability of default by age groups:\")\nprint(age_groups_probabilities)\nprint(\"\\nAverage predicted probability of default by loan intent:\")\nprint(loan_intent_probabilities)\nprint(\"\\nAverage predicted probability of default by income levels:\")\nprint(income_levels_probabilities)\nprint(\"\\nActual default rate:\", actual_default_rate)"
  },
  {
    "objectID": "posts/Mid-Course/mid-course.html",
    "href": "posts/Mid-Course/mid-course.html",
    "title": "Instructions",
    "section": "",
    "text": "Download this notebook\nOpen the notebook in an editor of your choice (I recommend either VSCode or JupyterLab).\nDelete the first two cells of the notebook (i.e. this one and the raw cell above).\nBriefly review the goals you set for yourself in our goal-setting activity at the beginning of the course. You can find your goals on Canvas.\nIn the The Data section, replace the blanks with brief responses.\nIn the What You Learned and Reflecting on Goals sections, write down your reflections on your learning, achievement, and presence in CSCI 0451 in the provided markdown cells.\nTake some time to reflect on your responses so far. When you’re ready, review the soundbytes describing letter grades.\nTake some time to reflect on your responses so far. When you’re ready, propose the letter grade that you feel best reflects your learning, participation, and achievement in CSCI 0451 so far.\nOptionally, respond to the last prompt with some thoughts on how the semester is going and what we might do to help you meet your goals for the course.\nSubmit the notebook as a PDF on Canvas.\n\nWe’ll discuss your reflection and your proposed letter grade during our end-of-semester conference.\nThere are lots of ways to render Jupyter notebooks as PDFs. The simplest way is to run this at the command line, after you’ve navigated to the location of the notebook:\njupyter nbconvert --to pdf mid-course.ipynb"
  },
  {
    "objectID": "posts/Mid-Course/mid-course.html#the-data",
    "href": "posts/Mid-Course/mid-course.html#the-data",
    "title": "Instructions",
    "section": "The Data",
    "text": "The Data\nIn this section I’ll ask you to fill in some data. You don’t have to give precise numbers – approximate, conversational responses are fine. For example, when I ask “how often have you attended class,” good answers include “almost always,” “I’ve missed three times,” “about 75% of the time,” “not as often as I want,” etc.\n\nPresence in Class\n\nHow often have you attended class? (e.g. “almost always,” “I missed three times,” etc.) I have missed a few times, only when I had other appointments\nHow often have you taken notes on the core readings ahead of the class period? never\nHow often have you been prepared to present the daily warm-up exercise to your team, even if you weren’t actually called? pretty much every day except the day I was called to present\nHow many times have you actually presented the daily warm-up to your team? 1\nHow many times have you asked your team for help while presenting the daily warm-up? 1\nHow often have you learned something new from a teammate’s presentation of the daily warm-up? most days\nHow often have you helped a teammate during the daily warm-up presentation? quite often, when help is needed\n\n\n\nPresence Outside of Class\n\nHow often have you attended Student Hours or Peer Help? once\nHow often have you asked for or received help from your fellow students? several times\nHave you been regularly participating in a study group outside class? no\nHow often have you posted questions or answers in Slack? have asked direct questions\n\n\n\nAssignments and Effort\n\nHow many blog posts have you submitted? one\nHow many of your submitted blog posts are at each of the following feedback stages?\n\nE: No revisions suggested: ____\nM: Revisions useful: ____\nR: Revisions encouraged: 1\nN: Incomplete: ____\n\nRoughly how many hours per week have you spent on this course outside of class? 4"
  },
  {
    "objectID": "posts/Mid-Course/mid-course.html#what-youve-learned",
    "href": "posts/Mid-Course/mid-course.html#what-youve-learned",
    "title": "Instructions",
    "section": "What You’ve Learned",
    "text": "What You’ve Learned\nAt the beginning of the course, you may have expressed an interest in focusing a little extra on one or two of the following four categories:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nDid you choose to focus on any of these categories? If so, what have you done in order to pursue your interest?\nI wanted to focus mostly on social responsibility, as this pertains mostly to what I am interested in outside of academic contexts, and I feel I have learned a great deal about social contexts in Machine Learning. The in-class activities about bias and data collection strategies, as well as the bias replication study I did for a blog post, have showed me a lot of ways that machine learning technologies can be unfairly biased.\nI also wanted to grow in my math knowledge, having not taken a math class since high school, and I have (somewhat surprisingly) really enjoyed regaining my calculus knowledge and understanding equations we use in our programs."
  },
  {
    "objectID": "posts/Mid-Course/mid-course.html#reflecting-on-goals",
    "href": "posts/Mid-Course/mid-course.html#reflecting-on-goals",
    "title": "Instructions",
    "section": "Reflecting on Goals",
    "text": "Reflecting on Goals\nFor each of the categories below, replace the “[your response here]” cell with 1-2 paragraphs in which you reflect on the following questions:\n\nIn what ways are you on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what you are doing in order to meet it.\nIn what ways are you not on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what gap you see between where you are and your goal.\nIf there’s any context you want to share about how you are faring relative to your goals, please do!\n\n\nBlog Posts\nMy goal was to complete two-thirds of the blog posts, and as I have only completed one, I am definitely not on track with that goal. I think I overestimated the amount of time and energy I would have to spend on blog posts, especially when I am not planning on using machine learning or programming knowledge in my post-graduate career, and I would like to alter my goal to completing at least three blog posts in total. I would like to allocate more of my energy for this class toward my final project, where I can choose what topics interest me and can motivate myself to invest more energy in it.\n\n\nCourse Presence (Participation)\nI have attended all classes that I could and participated in my group warmu-up discussions. I will continue to come prepared with the warm-up each day and engage with my group in every class.\n\n\nProject\nI would like to continue learning about social biases in machine learning. Many methods we’ve studied have been effective in identifying disparities in pre-existing data related to various topics, and I would like to find an existing dataset we haven’t looked at and apply a machine learning algorithm to it to find and visualize social disparities.\n\n\nOther\nIs there anything else that you want to share with me about what you have learned, how you have participated, or what you have achieved in CSCI 0451?\n[your response here]\n\n\nUpdating Your Goals\nFrom your experience in CSCI 0451 and your other classes this semester, you may feel moved to make modifications to your goals. Are they still feasible? Too ambitious? Not ambitious enough? If you would like to revise any of your goals from your reflective goal-setting, you can do so below. For each goal you want to modify:\n\nClearly state what the goal was.\nClearly state how you’ve done on that goal so far.\nClearly state your proposed revised goal for the remainder of the course.\n\nMy goal for was to complete two thirds of the assigned blog posts. I am not nearly on track to do this, as I have completed one blog post with revision still to do. I am recognizing that work in all of my classes will only increase as the semester’s end approaches and I begin to start work on final projects for each class, so I would like to revise my goal to complete three total blog posts, which leaves two remaining for me to do in the second half of the semester."
  },
  {
    "objectID": "posts/Mid-Course/mid-course.html#grade-and-goals",
    "href": "posts/Mid-Course/mid-course.html#grade-and-goals",
    "title": "Instructions",
    "section": "Grade and Goals",
    "text": "Grade and Goals\nTake 15 minutes to look back on your responses in each of the sections above. Then, state the letter grade that you feel reflects your learning, participation, and achievement in CSCI 0451 so far, and contextualize it against some of the soundbytes below.\n\nWhat a Grade Sounds Like\nAn A sounds like:\n\n“I am very proud of my time in this course.”\n“I have grown significantly in multiple ways that matter to me.”\n“I am ready to take the theory, techniques, and ideas of this course into my future classes, projects, hobbies, or career.”\n\nA B sounds like:\n\n“I had some opportunities to learn more, overall I feel good about my time in this course.”\n“I am able to explain some new things or achieve new tasks.”\n“I can see a few ideas from this course that will be relevant for my future classes, projects, hobbies, or career.”\n\nA C sounds like:\n\n“I often made a good effort, but I missed many opportunities to get more out of my time in this course.”\n“I might be able to complete some new tasks related to the course content, but only with significant further guidance.”\n“I don’t see any ways to take the contents of this course into my future classes, projects, hobbies, or career.”\n\nYou might find that some of these soundbytes resonate and other’s don’t! Take some time, see what feels right, and don’t be afraid to celebrate your achievements.\n\nUpon reflection, I feel that my learning, participation, and achievement in CSCI 0451 (so far) are best reflected by a grade of B\n\n\nA way in which I resonate with the soundbytes for that grade above is… I definitely feel good overall about what I have learned and achieved in this course, even if there are not many physical products of my work to attest to this. Going into the class, I knew it would be challenging material and challenging to motivate myself to learn all I can because this is my last semester as a CS student, but I am happy with how much I have mentally engaged with the material and with the topics in lectures. I have appreciated the emphasis on uses of machine learning in social contexts, rather than just learning different algorithms with no broader context. I am confident that this part of the class, which emphasizes bias, prejudice, and social disparity, will be useful to me outside the context of this class. I have also grown a lot in my math knowledge and will continue to do so throughout the remainder of the course. I can confidently say I can achieve new tasks that I was not able to before this class. While I could have expanded my learning with more blog posts and work outside of class, I know I have learned a great deal that I can take with me and use in my personal life outside of Midd."
  },
  {
    "objectID": "posts/Mid-Course/mid-course.html#optional-how-to-improve",
    "href": "posts/Mid-Course/mid-course.html#optional-how-to-improve",
    "title": "Instructions",
    "section": "(Optional:) How to Improve?",
    "text": "(Optional:) How to Improve?\nYou may feel disappointed by your reflection. Sometimes we don’t achieve all our goals – it happens and it’s normal! If you are feeling disappointed by how you’ve learned, participated, or achieved in CSCI 0451, then feel free to write something about that below. Feel free to just write your feelings. If you have ideas for how to move forward, include those too! We’ll talk.\n[your response here]"
  },
  {
    "objectID": "LinearModels_Perceptron_Torch.html",
    "href": "LinearModels_Perceptron_Torch.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "import torch\n\ntorch.manual_seed(1234)\n\ndef perceptron_data(n_points = 300, noise = 0.2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,2))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # convert y from {0, 1} to {-1, 1}\n    y = 2*y - 1\n\n    return X, y\n\nX, y = perceptron_data(n_points = 300, noise = 0.2)\n\n\nimport torch\n\nclass LinearModel:\n\n    def __init__(self):\n        self.w = None \n\n    def score(self, X):\n        \"\"\"\n        Compute the scores for each data point in the feature matrix X. \n        The formula for the ith entry of s is s[i] = &lt;self.w, x[i]&gt;. \n\n        If self.w currently has value None, then it is necessary to first initialize self.w to a random value. \n\n        ARGUMENTS: \n            X, torch.Tensor: the feature matrix. X.size() == (n, p), \n            where n is the number of data points and p is the \n            number of features. This implementation always assumes \n            that the final column of X is a constant column of 1s. \n\n        RETURNS: \n            s torch.Tensor: vector of scores. s.size() = (n,)\n        \"\"\"\n        if self.w is None: \n            self.w = torch.rand((X.size()[1]))\n\n        # your computation here: compute the vector of scores s\n        pass \n\n    def predict(self, X):\n        \"\"\"\n        Compute the predictions for each data point in the feature matrix X. The prediction for the ith data point is either 0 or 1. \n\n        ARGUMENTS: \n            X, torch.Tensor: the feature matrix. X.size() == (n, p), \n            where n is the number of data points and p is the \n            number of features. This implementation always assumes \n            that the final column of X is a constant column of 1s. \n\n        RETURNS: \n            y_hat, torch.Tensor: vector predictions in {0.0, 1.0}. y_hat.size() = (n,)\n        \"\"\"\n        pass \n\nclass Perceptron(LinearModel):\n\n    def loss(self, X, y):\n        \"\"\"\n        Compute the misclassification rate. A point i is classified correctly if it holds that s_i*y_i_ &gt; 0, where y_i_ is the *modified label* that has values in {-1, 1} (rather than {0, 1}). \n\n        ARGUMENTS: \n            X, torch.Tensor: the feature matrix. X.size() == (n, p), \n            where n is the number of data points and p is the \n            number of features. This implementation always assumes \n            that the final column of X is a constant column of 1s. \n\n            y, torch.Tensor: the target vector.  y.size() = (n,). The possible labels for y are {0, 1}\n        \n        HINT: In order to use the math formulas in the lecture, you are going to need to construct a modified set of targets and predictions that have entries in {-1, 1} -- otherwise none of the formulas will work right! An easy to to make this conversion is: \n        \n        y_ = 2*y - 1\n        \"\"\"\n\n        # replace with your implementation\n        pass\n\n    def grad(self, X, y):\n        pass \n\nclass PerceptronOptimizer:\n\n    def __init__(self, model):\n        self.model = model \n    \n    def step(self, X, y):\n        \"\"\"\n        Compute one step of the perceptron update using the feature matrix X \n        and target vector y. \n        \"\"\"\n        pass"
  },
  {
    "objectID": "Convexity-Warmup.html",
    "href": "Convexity-Warmup.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\n# Generate values for z\nz_values = np.linspace(-1, 1, 100)\n\n# Calculate sigmoid values\nsigmoid_values = sigmoid(z_values)\n\n# Plot sigmoid function\nplt.plot(z_values, sigmoid_values, label='Sigmoid Function')\nplt.title('Sigmoid Function')\nplt.xlabel('z')\nplt.ylabel('sigma(z)')\nplt.grid(True)\nplt.legend()"
  },
  {
    "objectID": "mid-course.html",
    "href": "mid-course.html",
    "title": "Instructions",
    "section": "",
    "text": "Download this notebook\nOpen the notebook in an editor of your choice (I recommend either VSCode or JupyterLab).\nDelete the first two cells of the notebook (i.e. this one and the raw cell above).\nBriefly review the goals you set for yourself in our goal-setting activity at the beginning of the course. You can find your goals on Canvas.\nIn the The Data section, replace the blanks with brief responses.\nIn the What You Learned and Reflecting on Goals sections, write down your reflections on your learning, achievement, and presence in CSCI 0451 in the provided markdown cells.\nTake some time to reflect on your responses so far. When you’re ready, review the soundbytes describing letter grades.\nTake some time to reflect on your responses so far. When you’re ready, propose the letter grade that you feel best reflects your learning, participation, and achievement in CSCI 0451 so far.\nOptionally, respond to the last prompt with some thoughts on how the semester is going and what we might do to help you meet your goals for the course.\nSubmit the notebook as a PDF on Canvas.\n\nWe’ll discuss your reflection and your proposed letter grade during our end-of-semester conference.\nThere are lots of ways to render Jupyter notebooks as PDFs. The simplest way is to run this at the command line, after you’ve navigated to the location of the notebook:\njupyter nbconvert --to pdf mid-course.ipynb"
  },
  {
    "objectID": "mid-course.html#the-data",
    "href": "mid-course.html#the-data",
    "title": "Instructions",
    "section": "The Data",
    "text": "The Data\nIn this section I’ll ask you to fill in some data. You don’t have to give precise numbers – approximate, conversational responses are fine. For example, when I ask “how often have you attended class,” good answers include “almost always,” “I’ve missed three times,” “about 75% of the time,” “not as often as I want,” etc.\n\nPresence in Class\n\nHow often have you attended class? (e.g. “almost always,” “I missed three times,” etc.) I have missed a few times, only when I had other appointments\nHow often have you taken notes on the core readings ahead of the class period? never\nHow often have you been prepared to present the daily warm-up exercise to your team, even if you weren’t actually called? pretty much every day except the day I was called to present\nHow many times have you actually presented the daily warm-up to your team? 1\nHow many times have you asked your team for help while presenting the daily warm-up? 1\nHow often have you learned something new from a teammate’s presentation of the daily warm-up? most days\nHow often have you helped a teammate during the daily warm-up presentation? quite often, when help is needed\n\n\n\nPresence Outside of Class\n\nHow often have you attended Student Hours or Peer Help? once\nHow often have you asked for or received help from your fellow students? several times\nHave you been regularly participating in a study group outside class? no\nHow often have you posted questions or answers in Slack? have asked direct questions\n\n\n\nAssignments and Effort\n\nHow many blog posts have you submitted? one\nHow many of your submitted blog posts are at each of the following feedback stages?\n\nE: No revisions suggested: ____\nM: Revisions useful: ____\nR: Revisions encouraged: 1\nN: Incomplete: ____\n\nRoughly how many hours per week have you spent on this course outside of class? 4"
  },
  {
    "objectID": "mid-course.html#what-youve-learned",
    "href": "mid-course.html#what-youve-learned",
    "title": "Instructions",
    "section": "What You’ve Learned",
    "text": "What You’ve Learned\nAt the beginning of the course, you may have expressed an interest in focusing a little extra on one or two of the following four categories:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nDid you choose to focus on any of these categories? If so, what have you done in order to pursue your interest?\nI wanted to focus mostly on social responsibility, as this pertains mostly to what I am interested in outside of academic contexts, and I feel I have learned a great deal about social contexts in Machine Learning. The in-class activities about bias and data collection strategies, as well as the bias replication study I did for a blog post, have showed me a lot of ways that machine learning technologies can be unfairly biased.\nI also wanted to grow in my math knowledge, having not taken a math class since high school, and I have (somewhat surprisingly) really enjoyed regaining my calculus knowledge and understanding equations we use in our programs."
  },
  {
    "objectID": "mid-course.html#reflecting-on-goals",
    "href": "mid-course.html#reflecting-on-goals",
    "title": "Instructions",
    "section": "Reflecting on Goals",
    "text": "Reflecting on Goals\nFor each of the categories below, replace the “[your response here]” cell with 1-2 paragraphs in which you reflect on the following questions:\n\nIn what ways are you on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what you are doing in order to meet it.\nIn what ways are you not on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what gap you see between where you are and your goal.\nIf there’s any context you want to share about how you are faring relative to your goals, please do!\n\n\nBlog Posts\nMy goal was to complete two-thirds of the blog posts, and as I have only completed one, I am definitely not on track with that goal. I think I overestimated the amount of time and energy I would have to spend on blog posts, especially when I am not planning on using machine learning or programming knowledge in my post-graduate career, and I would like to alter my goal to completing at least three blog posts in total. I would like to allocate more of my energy for this class toward my final project, where I can choose what topics interest me and can motivate myself to invest more energy in it.\n\n\nCourse Presence (Participation)\nI have attended all classes that I could and participated in my group warmu-up discussions. I will continue to come prepared with the warm-up each day and engage with my group in every class.\n\n\nProject\nI would like to continue learning about social biases in machine learning. Many methods we’ve studied have been effective in identifying disparities in pre-existing data related to various topics, and I would like to find an existing dataset we haven’t looked at and apply a machine learning algorithm to it to find and visualize social disparities.\n\n\nOther\nIs there anything else that you want to share with me about what you have learned, how you have participated, or what you have achieved in CSCI 0451?\n[your response here]\n\n\nUpdating Your Goals\nFrom your experience in CSCI 0451 and your other classes this semester, you may feel moved to make modifications to your goals. Are they still feasible? Too ambitious? Not ambitious enough? If you would like to revise any of your goals from your reflective goal-setting, you can do so below. For each goal you want to modify:\n\nClearly state what the goal was.\nClearly state how you’ve done on that goal so far.\nClearly state your proposed revised goal for the remainder of the course.\n\nMy goal for was to complete two thirds of the assigned blog posts. I am not nearly on track to do this, as I have completed one blog post with revision still to do. I am recognizing that work in all of my classes will only increase as the semester’s end approaches and I begin to start work on final projects for each class, so I would like to revise my goal to complete three total blog posts, which leaves two remaining for me to do in the second half of the semester."
  },
  {
    "objectID": "mid-course.html#grade-and-goals",
    "href": "mid-course.html#grade-and-goals",
    "title": "Instructions",
    "section": "Grade and Goals",
    "text": "Grade and Goals\nTake 15 minutes to look back on your responses in each of the sections above. Then, state the letter grade that you feel reflects your learning, participation, and achievement in CSCI 0451 so far, and contextualize it against some of the soundbytes below.\n\nWhat a Grade Sounds Like\nAn A sounds like:\n\n“I am very proud of my time in this course.”\n“I have grown significantly in multiple ways that matter to me.”\n“I am ready to take the theory, techniques, and ideas of this course into my future classes, projects, hobbies, or career.”\n\nA B sounds like:\n\n“I had some opportunities to learn more, overall I feel good about my time in this course.”\n“I am able to explain some new things or achieve new tasks.”\n“I can see a few ideas from this course that will be relevant for my future classes, projects, hobbies, or career.”\n\nA C sounds like:\n\n“I often made a good effort, but I missed many opportunities to get more out of my time in this course.”\n“I might be able to complete some new tasks related to the course content, but only with significant further guidance.”\n“I don’t see any ways to take the contents of this course into my future classes, projects, hobbies, or career.”\n\nYou might find that some of these soundbytes resonate and other’s don’t! Take some time, see what feels right, and don’t be afraid to celebrate your achievements.\n\nUpon reflection, I feel that my learning, participation, and achievement in CSCI 0451 (so far) are best reflected by a grade of B\n\n\nA way in which I resonate with the soundbytes for that grade above is… I definitely feel good overall about what I have learned and achieved in this course, even if there are not many physical products of my work to attest to this. Going into the class, I knew it would be challenging material and challenging to motivate myself to learn all I can because this is my last semester as a CS student, but I am happy with how much I have mentally engaged with the material and with the topics in lectures. I have appreciated the emphasis on uses of machine learning in social contexts, rather than just learning different algorithms with no broader context. I am confident that this part of the class, which emphasizes bias, prejudice, and social disparity, will be useful to me outside the context of this class. I have also grown a lot in my math knowledge and will continue to do so throughout the remainder of the course. I can confidently say I can achieve new tasks that I was not able to before this class. While I could have expanded my learning with more blog posts and work outside of class, I know I have learned a great deal that I can take with me and use in my personal life outside of Midd."
  },
  {
    "objectID": "mid-course.html#optional-how-to-improve",
    "href": "mid-course.html#optional-how-to-improve",
    "title": "Instructions",
    "section": "(Optional:) How to Improve?",
    "text": "(Optional:) How to Improve?\nYou may feel disappointed by your reflection. Sometimes we don’t achieve all our goals – it happens and it’s normal! If you are feeling disappointed by how you’ve learned, participated, or achieved in CSCI 0451, then feel free to write something about that below. Feel free to just write your feelings. If you have ideas for how to move forward, include those too! We’ll talk.\n[your response here]"
  },
  {
    "objectID": "posts/bias-replication-post/Bias-Replication.html#finding-disparities-in-risk-score-percentile-by-mean-chronic-illnesses",
    "href": "posts/bias-replication-post/Bias-Replication.html#finding-disparities-in-risk-score-percentile-by-mean-chronic-illnesses",
    "title": "Bias Replication Study",
    "section": "",
    "text": "In this figure we plot risk score percentile by the mean number of chronic illnesses within each percentile, with data points separated by race. Here we see a clear difference between races, with white patients more likely to be given a higher risk score than Black patients with the same number of chronic illnesses. If Patient A were white and Patient B were Black, and both patients had the same chronic illnesses, Patient A would be significantly more likely to have a higher risk score and be referred to a high-risk care management program.\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Calculate risk score percentiles\ndf['risk_score_percentile'] = df['risk_score_t'].rank(pct=True).round(2)\n\n\n# Calculate mean number of gagne_sum_t within each risk score percentile\nmean_gagne_per_percentile = df.groupby(['risk_score_percentile', 'race'])['gagne_sum_t'].mean().reset_index()\n\n\n# Plot\nsns.scatterplot(data=mean_gagne_per_percentile, x='gagne_sum_t', y='risk_score_percentile', hue='race', style='race')\nplt.xlabel('Mean Chronic Illnesses')\nplt.ylabel('Risk Score Percentile')\nplt.xlim(0,8)\nplt.show()"
  },
  {
    "objectID": "posts/bias-replication-post/Bias-Replication.html#racial-disparity-in-medical-expenses-by-chronic-illnesses-and-risk-score",
    "href": "posts/bias-replication-post/Bias-Replication.html#racial-disparity-in-medical-expenses-by-chronic-illnesses-and-risk-score",
    "title": "Bias Replication Study",
    "section": "",
    "text": "Here we explore differences in cost incurred by Black and white patients with various risk scores and various numbers of chronic illnesses. These figures suggest that, for Black patients, as risk score and number of chronic illnesses increase, medical expenditures increase at a higher rate than that of white patients. For lower risk scores and chronic illness counts, white patients seem to have slightly higher medical costs than for Black patients, but it appears as though Black patients are penalized more severely for having more illnesses and being of higher risk.\n\n#group data with risk score percentile and cost\ndf_cost = df.groupby(['risk_score_percentile', 'race'])['cost_t'].mean().reset_index()\n\n#group data with number of chronic illnesses and cost\ndf_cost2 = df.groupby(['gagne_sum_t', 'race'])['cost_t'].mean().reset_index()\n\n\nfig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 5))\n\n#plot cost by percentile risk score\np1 = sns.scatterplot(data=df_cost, x='risk_score_percentile', y='cost_t', hue='race', style='race', ax = ax1)\np1.set_xlabel('Percentile Risk Score')\np1.set_ylabel('Total Medical Expenditures')\nplt.gca().semilogy()\n\n#plot cost by number of chronic illnesses\np2 = sns.scatterplot(data=df_cost2, x='gagne_sum_t', y='cost_t', hue='race', style='race', ax = ax2)\np2.set_xlabel('Number of Chronic Illnesses')\np2.set_ylabel('Total Medical Expenditures')\nplt.gca().semilogy()\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\n\n# Calculate the percentage of patients with 5 or fewer chronic conditions\npercentage = (len(df[df['gagne_sum_t'] &lt;= 5]) / len(df)) * 100\n\n# 95.53952115447689 - choice to use patients with 5 or fewer chronic conditions makes sense, \n# as 96% of patients have 5 or fewer chronic conditions.\n\n# Eliminate subjects with 0 cost, perform log function on cost column\ndf = df[df['cost_t'] &gt; 0]\ndf['log_cost'] = df['cost_t'].apply(lambda x: np.log(x))\n\n# Create a dummy column for the race variable\ndf['race_encoded'] = pd.get_dummies(df['race'], drop_first=True)\n\n# Separate the data into predictor variables (X) and target variable (y)\nX = df[['race_encoded', 'gagne_sum_t']]\ny = df['log_cost']"
  },
  {
    "objectID": "posts/bias-replication-post/Bias-Replication.html#logistic-regression-for-medical-costs-given-number-of-chronic-illnesses.",
    "href": "posts/bias-replication-post/Bias-Replication.html#logistic-regression-for-medical-costs-given-number-of-chronic-illnesses.",
    "title": "Bias Replication Study",
    "section": "",
    "text": "from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Function to add polynomial features\ndef add_polynomial_features(X, degree):\n    X_ = X.copy()\n    for j in range(1, degree):\n        X_[f\"poly_{j}\"] = X_[\"gagne_sum_t\"]**j\n    return X_\n\n# Create different degrees of polynomial features and compute cross-validation scores\ndegrees = range(1, 15)\nscores = []\n\nfor degree in degrees:\n    # Add polynomial features\n    X_poly = add_polynomial_features(X, degree)\n    \n    # Perform cross-validation with linear regression\n    lr = LinearRegression()\n    cv_score = cross_val_score(lr, X_poly, y, cv=5).mean()\n    scores.append(cv_score)\n\n# Determine the optimal degree based on cross-validation scores\noptimal_degree = degrees[np.argmax(scores)]\nprint(\"Optimal degree based on cross-validation:\", optimal_degree)\n\n# Construct data with the optimal number of polynomial features\nX_poly_optimal = add_polynomial_features(X, optimal_degree)\n\n# Fit the final linear regression model\nlr_final = LinearRegression()\nlr_final.fit(X_poly_optimal, y)\n\n# Get coefficients of the linear regression model\ncoefficients = lr_final.coef_\n\n\n# Identify the coefficient corresponding to the Black race\nwb = coefficients[-1]\nprint(\"w_b: \", wb)\n\n# Compute e^wb\ne_wb = np.exp(wb)\nprint(\"e^w_b: \", e_wb)\n\nOptimal degree based on cross-validation: 10\nw_b:  9.390071033164823e-08\ne^w_b:  1.0000000939007148\n\n\nThis linear regression model worked best with cross validation on 10 polynomial degrees. After fitting the final linear regression model, the value I received for e^(w_b) was 1.0000000939007148, indicating that a Black patient pays slightly over 100% of the cost that an equally sick white patient must pay."
  },
  {
    "objectID": "posts/bias-replication-post/Bias-Replication.html#discussion",
    "href": "posts/bias-replication-post/Bias-Replication.html#discussion",
    "title": "Bias Replication Study",
    "section": "",
    "text": "The above plots give visual representations of racial disparities in medical care, and the logistic regression models slight disparities in cost incurred by equally sick patients. However, while this value of slightly more than 100% may seem like only a minor difference, it could be suggested that the value extracted from the regression does not account for the kinds of disparities that are present. As we see in the Medical Expenditure Plots above, as Risk Score Percentile and Number of Chronic Illnesses increase, so does the different in cost between Black and white patients. While white patients might pay as much as or more than Black patients for lower-risk, less severe conditions, Black patients are financially penalized as their conditions become more severe, and the logistic regression does not account for this idea. The plots clearly model differences in the way Black and white patients are treated, specifically of Barocas et al’s discrimination criterion of “outcome frequency given score value”. If these observations were “fair”, statistics for Black and white patients would be about equal, given that their medical conditions are identical. However, we do see clear outliers and differing trends between patients of different race but identical medical conditions, scoring Black patients at significantly lower risk than equally sick white patients and with high-risk Black patients incurring significantly higher medical costs than equally sick white patients."
  }
]