[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/new-new-test-post/index.html",
    "href": "posts/new-new-test-post/index.html",
    "title": "Timnit Gebru",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-new-test-post/index.html#math",
    "href": "posts/new-new-test-post/index.html#math",
    "title": "Timnit Gebru",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "from source import Perceptron\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "This is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "Implementing Logistic Regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBias Replication Study\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLimits to the Quantitative Approach to Bias and Fairness\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/bias-replication-post/Bias-Replication.html",
    "href": "posts/bias-replication-post/Bias-Replication.html",
    "title": "Bias Replication Study",
    "section": "",
    "text": "This data frame represents disparities in medical data, including medical cost, risk score, and number of chronic illnesses, between Black and white patients. The plots shown are visual representations of such disparities, replicating studies by Obermeyer et al. in 2019 article “Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations.” These plots show clear distinctions between the costs incurred by Black and white patients and the likelihood of being referred to a high-risk medical program for a given number of illnesses. The linear regression I performed displays logarithmic coefficient w_b, which, when presented as \\(e^(w_b)\\), represents the percentage of a white patient’s cost that a Black patient must pay. My calculation revealed that a Black patient pays over 100% of what a white patient pays for the same illness(es), supporting the idea that racial disparities are prevalent in healthcare.\n\nimport pandas as pd\nurl = \"https://gitlab.com/labsysmed/dissecting-bias/-/raw/master/data/data_new.csv?inline=false\"\ndf = pd.read_csv(url)\ndf\n\n\n\n\n\n\n\n\nrisk_score_t\nprogram_enrolled_t\ncost_t\ncost_avoidable_t\nbps_mean_t\nghba1c_mean_t\nhct_mean_t\ncre_mean_t\nldl_mean_t\nrace\n...\ntrig_min-high_tm1\ntrig_min-normal_tm1\ntrig_mean-low_tm1\ntrig_mean-high_tm1\ntrig_mean-normal_tm1\ntrig_max-low_tm1\ntrig_max-high_tm1\ntrig_max-normal_tm1\ngagne_sum_tm1\ngagne_sum_t\n\n\n\n\n0\n1.987430\n0\n1200.0\n0.0\nNaN\n5.4\nNaN\n1.110000\n194.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n7.677934\n0\n2600.0\n0.0\n119.0\n5.5\n40.4\n0.860000\n93.0\nwhite\n...\n0\n1\n0\n0\n1\n0\n0\n1\n4\n3\n\n\n2\n0.407678\n0\n500.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0.798369\n0\n1300.0\n0.0\n117.0\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n17.513165\n0\n1100.0\n0.0\n116.0\nNaN\n34.1\n1.303333\n53.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n48779\n0.611517\n0\n800.0\n0.0\nNaN\nNaN\nNaN\n1.090000\n148.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n48780\n2.615933\n0\n2200.0\n0.0\n112.0\nNaN\n41.4\n0.810000\n172.0\nwhite\n...\n0\n1\n0\n0\n1\n0\n0\n1\n1\n1\n\n\n48781\n1.358926\n0\n800.0\n0.0\n105.0\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n1\n0\n0\n1\n0\n0\n1\n1\n0\n\n\n48782\n10.990318\n0\n1300.0\n0.0\n132.0\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n3\n3\n\n\n48783\n1.681671\n0\n4400.0\n0.0\n115.0\n5.6\n36.6\n0.940000\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n48784 rows × 160 columns\n\n\n\n\n\n\nIn this figure we plot risk score percentile by the mean number of chronic illnesses within each percentile, with data points separated by race. Here we see a clear difference between races, with white patients more likely to be given a higher risk score than Black patients with the same number of chronic illnesses. If Patient A were white and Patient B were Black, and both patients had the same chronic illnesses, Patient A would be significantly more likely to have a higher risk score and be referred to a high-risk care management program.\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Calculate risk score percentiles\ndf['risk_score_percentile'] = df['risk_score_t'].rank(pct=True).round(2)\n\n\n# Calculate mean number of gagne_sum_t within each risk score percentile\nmean_gagne_per_percentile = df.groupby(['risk_score_percentile', 'race'])['gagne_sum_t'].mean().reset_index()\n\n\n# Plot\nsns.scatterplot(data=mean_gagne_per_percentile, x='gagne_sum_t', y='risk_score_percentile', hue='race', style='race')\nplt.xlabel('Mean Chronic Illnesses')\nplt.ylabel('Risk Score Percentile')\nplt.xlim(0,8)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nHere we explore differences in cost incurred by Black and white patients with various risk scores and various numbers of chronic illnesses. These figures suggest that, for Black patients, as risk score and number of chronic illnesses increase, medical expenditures increase at a higher rate than that of white patients. For lower risk scores and chronic illness counts, white patients seem to have slightly higher medical costs than for Black patients, but it appears as though Black patients are penalized more severely for having more illnesses and being of higher risk.\n\n#group data with risk score percentile and cost\ndf_cost = df.groupby(['risk_score_percentile', 'race'])['cost_t'].mean().reset_index()\n\n#group data with number of chronic illnesses and cost\ndf_cost2 = df.groupby(['gagne_sum_t', 'race'])['cost_t'].mean().reset_index()\n\n\nfig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 5))\n\n#plot cost by percentile risk score\np1 = sns.scatterplot(data=df_cost, x='risk_score_percentile', y='cost_t', hue='race', style='race', ax = ax1)\np1.set_xlabel('Percentile Risk Score')\np1.set_ylabel('Total Medical Expenditures')\nplt.gca().semilogy()\n\n#plot cost by number of chronic illnesses\np2 = sns.scatterplot(data=df_cost2, x='gagne_sum_t', y='cost_t', hue='race', style='race', ax = ax2)\np2.set_xlabel('Number of Chronic Illnesses')\np2.set_ylabel('Total Medical Expenditures')\nplt.gca().semilogy()\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\n\n# Calculate the percentage of patients with 5 or fewer chronic conditions\npercentage = (len(df[df['gagne_sum_t'] &lt;= 5]) / len(df)) * 100\n\n# 95.53952115447689 - choice to use patients with 5 or fewer chronic conditions makes sense, \n# as 96% of patients have 5 or fewer chronic conditions.\n\n# Eliminate subjects with 0 cost, perform log function on cost column\ndf = df[df['cost_t'] &gt; 0]\ndf['log_cost'] = df['cost_t'].apply(lambda x: np.log(x))\n\n# Create a dummy column for the race variable\ndf['race_encoded'] = pd.get_dummies(df['race'], drop_first=True)\n\n# Separate the data into predictor variables (X) and target variable (y)\nX = df[['race_encoded', 'gagne_sum_t']]\ny = df['log_cost']\n\n\n\n\n\n\n\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Function to add polynomial features\ndef add_polynomial_features(X, degree):\n    X_ = X.copy()\n    for j in range(1, degree):\n        X_[f\"poly_{j}\"] = X_[\"gagne_sum_t\"]**j\n    return X_\n\n# Create different degrees of polynomial features and compute cross-validation scores\ndegrees = range(1, 15)\nscores = []\n\nfor degree in degrees:\n    # Add polynomial features\n    X_poly = add_polynomial_features(X, degree)\n    \n    # Perform cross-validation with linear regression\n    lr = LinearRegression()\n    cv_score = cross_val_score(lr, X_poly, y, cv=5).mean()\n    scores.append(cv_score)\n\n# Determine the optimal degree based on cross-validation scores\noptimal_degree = degrees[np.argmax(scores)]\nprint(\"Optimal degree based on cross-validation:\", optimal_degree)\n\n# Construct data with the optimal number of polynomial features\nX_poly_optimal = add_polynomial_features(X, optimal_degree)\n\n# Fit the final linear regression model\nlr_final = LinearRegression()\nlr_final.fit(X_poly_optimal, y)\n\n# Get coefficients of the linear regression model\ncoefficients = lr_final.coef_\n\n\n# Identify the coefficient corresponding to the Black race\nwb = coefficients[-1]\nprint(\"w_b: \", wb)\n\n# Compute e^wb\ne_wb = np.exp(wb)\nprint(\"e^w_b: \", e_wb)\n\nOptimal degree based on cross-validation: 10\nw_b:  9.390071033164823e-08\ne^w_b:  1.0000000939007148\n\n\nThis linear regression model worked best with cross validation on 10 polynomial degrees. After fitting the final linear regression model, the value I received for e^(w_b) was 1.0000000939007148, indicating that a Black patient pays slightly over 100% of the cost that an equally sick white patient must pay.\n\n\n\nThe above plots give visual representations of racial disparities in medical care, and the logistic regression models slight disparities in cost incurred by equally sick patients. However, while this value of slightly more than 100% may seem like only a minor difference, it could be suggested that the value extracted from the regression does not account for the kinds of disparities that are present. As we see in the Medical Expenditure Plots above, as Risk Score Percentile and Number of Chronic Illnesses increase, so does the different in cost between Black and white patients. While white patients might pay as much as or more than Black patients for lower-risk, less severe conditions, Black patients are financially penalized as their conditions become more severe, and the logistic regression does not account for this idea. The plots clearly model differences in the way Black and white patients are treated, specifically of Barocas et al’s discrimination criterion of “outcome frequency given score value”. If these observations were “fair”, statistics for Black and white patients would be about equal, given that their medical conditions are identical. However, we do see clear outliers and differing trends between patients of different race but identical medical conditions, scoring Black patients at significantly lower risk than equally sick white patients and with high-risk Black patients incurring significantly higher medical costs than equally sick white patients.\n\n\n\nBarocas, Solon, Moritz Hardt, and Arvind Narayanan. 2023. Fairness and Machine Learning: Limitations and Opportunities. Cambridge, Massachusetts: The MIT Press.\nObermeyer, Ziad, Brian Powers, Christine Vogeli, and Sendhil Mullainathan. 2019. “Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations.” Science 366 (6464): 447–53. https://doi.org/10.1126/science.aax2342."
  },
  {
    "objectID": "posts/bias-replication-post/Bias-Replication.html#abstract",
    "href": "posts/bias-replication-post/Bias-Replication.html#abstract",
    "title": "Bias Replication Study",
    "section": "",
    "text": "This data frame represents disparities in medical data, including medical cost, risk score, and number of chronic illnesses, between Black and white patients. The plots shown are visual representations of such disparities, replicating studies by Obermeyer et al. in 2019 article “Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations.” These plots show clear distinctions between the costs incurred by Black and white patients and the likelihood of being referred to a high-risk medical program for a given number of illnesses. The linear regression I performed displays logarithmic coefficient w_b, which, when presented as \\(e^(w_b)\\), represents the percentage of a white patient’s cost that a Black patient must pay. My calculation revealed that a Black patient pays over 100% of what a white patient pays for the same illness(es), supporting the idea that racial disparities are prevalent in healthcare.\n\nimport pandas as pd\nurl = \"https://gitlab.com/labsysmed/dissecting-bias/-/raw/master/data/data_new.csv?inline=false\"\ndf = pd.read_csv(url)\ndf\n\n\n\n\n\n\n\n\nrisk_score_t\nprogram_enrolled_t\ncost_t\ncost_avoidable_t\nbps_mean_t\nghba1c_mean_t\nhct_mean_t\ncre_mean_t\nldl_mean_t\nrace\n...\ntrig_min-high_tm1\ntrig_min-normal_tm1\ntrig_mean-low_tm1\ntrig_mean-high_tm1\ntrig_mean-normal_tm1\ntrig_max-low_tm1\ntrig_max-high_tm1\ntrig_max-normal_tm1\ngagne_sum_tm1\ngagne_sum_t\n\n\n\n\n0\n1.987430\n0\n1200.0\n0.0\nNaN\n5.4\nNaN\n1.110000\n194.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n7.677934\n0\n2600.0\n0.0\n119.0\n5.5\n40.4\n0.860000\n93.0\nwhite\n...\n0\n1\n0\n0\n1\n0\n0\n1\n4\n3\n\n\n2\n0.407678\n0\n500.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0.798369\n0\n1300.0\n0.0\n117.0\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n17.513165\n0\n1100.0\n0.0\n116.0\nNaN\n34.1\n1.303333\n53.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n48779\n0.611517\n0\n800.0\n0.0\nNaN\nNaN\nNaN\n1.090000\n148.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n48780\n2.615933\n0\n2200.0\n0.0\n112.0\nNaN\n41.4\n0.810000\n172.0\nwhite\n...\n0\n1\n0\n0\n1\n0\n0\n1\n1\n1\n\n\n48781\n1.358926\n0\n800.0\n0.0\n105.0\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n1\n0\n0\n1\n0\n0\n1\n1\n0\n\n\n48782\n10.990318\n0\n1300.0\n0.0\n132.0\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n3\n3\n\n\n48783\n1.681671\n0\n4400.0\n0.0\n115.0\n5.6\n36.6\n0.940000\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n48784 rows × 160 columns"
  },
  {
    "objectID": "Optimal-Decision-Making.html",
    "href": "Optimal-Decision-Making.html",
    "title": "Intro: Optimal Decision Making",
    "section": "",
    "text": "Intro: Optimal Decision Making\nFairness - it does not seem fair that people who are most in need of loans are least likely to receive them.\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import validation\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf = pd.read_csv(url)\ndf = df.dropna()\ndf\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_home_ownership\nperson_emp_length\nloan_intent\nloan_grade\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_default_on_file\ncb_person_cred_hist_length\n\n\n\n\n1\n27\n98000\nRENT\n3.0\nEDUCATION\nC\n11750\n13.47\n0\n0.12\nY\n6\n\n\n2\n22\n36996\nRENT\n5.0\nEDUCATION\nA\n10000\n7.51\n0\n0.27\nN\n4\n\n\n3\n24\n26000\nRENT\n2.0\nMEDICAL\nC\n1325\n12.87\n1\n0.05\nN\n4\n\n\n4\n29\n53004\nMORTGAGE\n2.0\nHOMEIMPROVEMENT\nA\n15000\n9.63\n0\n0.28\nN\n10\n\n\n6\n21\n21700\nRENT\n2.0\nHOMEIMPROVEMENT\nD\n5500\n14.91\n1\n0.25\nN\n2\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n26059\n36\n150000\nMORTGAGE\n8.0\nEDUCATION\nA\n3000\n7.29\n0\n0.02\nN\n17\n\n\n26060\n23\n48000\nRENT\n1.0\nVENTURE\nA\n4325\n5.42\n0\n0.09\nN\n4\n\n\n26061\n22\n60000\nRENT\n0.0\nMEDICAL\nB\n15000\n11.71\n0\n0.25\nN\n4\n\n\n26062\n30\n144000\nMORTGAGE\n12.0\nPERSONAL\nC\n35000\n12.68\n0\n0.24\nN\n8\n\n\n26063\n25\n60000\nRENT\n5.0\nEDUCATION\nA\n21450\n7.29\n1\n0.36\nN\n4\n\n\n\n\n22907 rows × 12 columns\n\n\n\n\nBoxplot of Person Age by Loan Intent\nThis plot shows the concentration of ages for which each loan intent is most prevalent. As most loan recipients are young adults, between around 20 and 35, there isn’t a significant amount of variation between the categories, though there are some notable disparities. Education has a quite narrow concentration of ages and is focused between the ages of around 24 to 29, whereas Home Improvement loans are taken out mostly by 26 to 32-year-olds with plenty of outliers of older ages. This seems to make sense, as newer adults may not have the time or resources to focus on improving their homes as much as older, more mature adults might. People of a broad range of ages take out loans for Venture, Personal, and Debt Consolidation purposes, and Medical loans are taken out mostly by people in their late 20s and early 30s, again with outliers extending into much older ages.\n\ndf_age = df[[\"person_age\", \"loan_intent\"]]\n\nplt.figure(figsize=(10, 6))\nsns.boxplot(x='loan_intent', y='person_age', data=df_age)\nplt.xlabel('Loan Intent')\nplt.ylabel('Person Age')\nplt.title('Box Plot of Person Age by Loan Intent')\nplt.ylim(20, 60)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nScatter Plot of Loan Interest Rate by Person Age\nThis is quite a dense scatterplot, as there are very many subjects in this dataset, but it still allows us to see a pattern. Maximum loan interest rates seem to be highest around 24 years of age and steadily decrease as the loan recipient grows older. Specifically, around 50 years of age, loan interest rates peak around 16%, whereas the peak interest rate for 24-year-olds is 22%. This could be because younger people are more likely to fault on loans, as they may have less financial stability than older adults.\n\ndf_income = df[[\"person_age\", \"loan_int_rate\"]]\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x='person_age', y='loan_int_rate', data=df_income)\nplt.xlabel('Person Age')\nplt.ylabel('Loan Interest Rate')\nplt.title('Scatter Plot of Loan Interest Rate by Person Age')\nplt.xlim(20,60)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nFitting a Score Function\nI am choosing to examine how Person Income and Loan Percent Income contribute to Loan Status. I am using SciKitLearn’s Logistic Regression model to assign scores to my two x variables.\n\n#fit logistic regression model\ndf_train, df_test = train_test_split(df, test_size = 0.2, random_state = 123) # 20% test set\n\nX_train = df_train[[\"person_emp_length\", \"loan_int_rate\"]]\ny_train = df_train[[\"loan_status\"]].values.ravel()\n\nX_test = df_test[[\"person_emp_length\", \"loan_int_rate\"]]\ny_test = df_test[[\"loan_status\"]]\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# get model coefficients\ncoefficients = model.coef_\n\ndef linear_score(X, w):\n    return X@w\n\nw = model.coef_.squeeze()\ns = linear_score(X_train, w)\nw\n\narray([-0.04924616,  0.28220565])\n\n\n\nhist = plt.hist(s)\nlabs = plt.gca().set(xlabel = r\"Score $s$\", ylabel = \"Frequency\") \n\n\n\n\n\n\n\n\n\n# calculate profit for each loan\ndef calculate_expected_profit(scores, loan_amnts, loan_int_rates, t):\n    \n   # profit_default = loan_amnts*(1 + 0.25 * loan_int_rates)**3 - 1.7*loan_amnts\n    #profit_repaid = loan_amnts*(1 + 0.25 * loan_int_rates)**10 - loan_amnts\n    \n    \n    expected_profits = []\n    for s, a, i in zip(scores, loan_amnts, loan_int_rates):\n        #profit for expected repayment\n        if s &gt;= t:\n            expected_profits.append(a*(1 + 0.25 * i)**10 - a)\n        #profit for expected default\n        else:\n            expected_profits.append(a*(1 + 0.25 * i)**3 - 1.7*a)\n    \n    return np.array(expected_profits)\n\n# Evaluate expected profit for different thresholds\ndef choose_threshold(scores, loan_amnts, loan_int_rates):\n    # Initialize variables to track threshold and maximum profit\n    max_profit = float('-inf')\n    best_threshold = None\n    \n    # Iterate over possible thresholds\n    for threshold in scores:\n        # Calculate profit for each instance using the current threshold\n        profits = calculate_expected_profit(scores, loan_amnts, loan_int_rates, threshold)\n        \n        # Calculate total profit\n        total_profit = profits.sum()\n        \n        # Update best threshold if total profit is higher\n        if total_profit &gt; max_profit:\n            max_profit = total_profit\n            best_threshold = threshold\n    \n    return best_threshold\n\n\n\n\n# Choose threshold\nloan_amnts = df_train[[\"loan_amnt\"]].squeeze()\nloan_int_rates = df_train[[\"loan_int_rate\"]].squeeze()\nbest_threshold = choose_threshold(s, loan_amnts, loan_int_rates)\nprint(\"Best threshold:\", best_threshold)\n\nBest threshold: -4.21165258842873\n\n\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/test.csv\"\ndf_test = pd.read_csv(url)\n\n\ndf_test_X = df_test[[\"person_emp_length\", \"loan_int_rate\"]]\ntest_amnts = df_test[[\"loan_amnt\"]].squeeze()\ntest_rates = df_test[[\"loan_int_rate\"]].squeeze()\ntest_scores = linear_score(df_test_X, w)\ntest_profits = calculate_expected_profit(test_scores, test_amnts, test_rates, best_threshold)\ntest_profits\n\narray([8.51905969e+08, 1.42483647e+11, 6.40822286e+08, ...,\n       7.91880603e+09, 4.57162163e+10, 6.06741469e+09])\n\n\n\n# Add predicted probabilities to the test data\nX_test['predicted_probabilities'] = model.predict_proba(X_test)[:, 1]\n\n# 1. Is it more difficult for people in certain age groups to access credit?\n# Group by age groups and calculate the average predicted probability of default\nage_groups_probabilities = X_test.groupby(pd.cut(X_test['person_age'], bins=[20, 30, 40, 50, 60, 70, 80]))['predicted_probabilities'].mean()\n\n# 2. Is it more difficult for people to get loans for specific purposes?\n# Group by loan_intent and calculate the average predicted probability of default\nloan_intent_probabilities = X_test.groupby('loan_intent')['predicted_probabilities'].mean()\n\n# 3. How does a person's income level impact the ease of accessing credit?\n# Group by income levels and calculate the average predicted probability of default\nincome_levels_probabilities = X_test.groupby(pd.cut(X_test['person_income'], bins=[0, 50000, 100000, 150000, 200000, float('inf')]))['predicted_probabilities'].mean()\n\n# Compare with the actual default rate in each group\nactual_default_rate = y_test.mean()\n\n# Print the results\nprint(\"Average predicted probability of default by age groups:\")\nprint(age_groups_probabilities)\nprint(\"\\nAverage predicted probability of default by loan intent:\")\nprint(loan_intent_probabilities)\nprint(\"\\nAverage predicted probability of default by income levels:\")\nprint(income_levels_probabilities)\nprint(\"\\nActual default rate:\", actual_default_rate)"
  },
  {
    "objectID": "posts/Mid-Course/mid-course.html",
    "href": "posts/Mid-Course/mid-course.html",
    "title": "Instructions",
    "section": "",
    "text": "Download this notebook\nOpen the notebook in an editor of your choice (I recommend either VSCode or JupyterLab).\nDelete the first two cells of the notebook (i.e. this one and the raw cell above).\nBriefly review the goals you set for yourself in our goal-setting activity at the beginning of the course. You can find your goals on Canvas.\nIn the The Data section, replace the blanks with brief responses.\nIn the What You Learned and Reflecting on Goals sections, write down your reflections on your learning, achievement, and presence in CSCI 0451 in the provided markdown cells.\nTake some time to reflect on your responses so far. When you’re ready, review the soundbytes describing letter grades.\nTake some time to reflect on your responses so far. When you’re ready, propose the letter grade that you feel best reflects your learning, participation, and achievement in CSCI 0451 so far.\nOptionally, respond to the last prompt with some thoughts on how the semester is going and what we might do to help you meet your goals for the course.\nSubmit the notebook as a PDF on Canvas.\n\nWe’ll discuss your reflection and your proposed letter grade during our end-of-semester conference.\nThere are lots of ways to render Jupyter notebooks as PDFs. The simplest way is to run this at the command line, after you’ve navigated to the location of the notebook:\njupyter nbconvert --to pdf mid-course.ipynb"
  },
  {
    "objectID": "posts/Mid-Course/mid-course.html#the-data",
    "href": "posts/Mid-Course/mid-course.html#the-data",
    "title": "Instructions",
    "section": "The Data",
    "text": "The Data\nIn this section I’ll ask you to fill in some data. You don’t have to give precise numbers – approximate, conversational responses are fine. For example, when I ask “how often have you attended class,” good answers include “almost always,” “I’ve missed three times,” “about 75% of the time,” “not as often as I want,” etc.\n\nPresence in Class\n\nHow often have you attended class? (e.g. “almost always,” “I missed three times,” etc.) I have missed a few times, only when I had other appointments\nHow often have you taken notes on the core readings ahead of the class period? never\nHow often have you been prepared to present the daily warm-up exercise to your team, even if you weren’t actually called? pretty much every day except the day I was called to present\nHow many times have you actually presented the daily warm-up to your team? 1\nHow many times have you asked your team for help while presenting the daily warm-up? 1\nHow often have you learned something new from a teammate’s presentation of the daily warm-up? most days\nHow often have you helped a teammate during the daily warm-up presentation? quite often, when help is needed\n\n\n\nPresence Outside of Class\n\nHow often have you attended Student Hours or Peer Help? once\nHow often have you asked for or received help from your fellow students? several times\nHave you been regularly participating in a study group outside class? no\nHow often have you posted questions or answers in Slack? have asked direct questions\n\n\n\nAssignments and Effort\n\nHow many blog posts have you submitted? one\nHow many of your submitted blog posts are at each of the following feedback stages?\n\nE: No revisions suggested: ____\nM: Revisions useful: ____\nR: Revisions encouraged: 1\nN: Incomplete: ____\n\nRoughly how many hours per week have you spent on this course outside of class? 4"
  },
  {
    "objectID": "posts/Mid-Course/mid-course.html#what-youve-learned",
    "href": "posts/Mid-Course/mid-course.html#what-youve-learned",
    "title": "Instructions",
    "section": "What You’ve Learned",
    "text": "What You’ve Learned\nAt the beginning of the course, you may have expressed an interest in focusing a little extra on one or two of the following four categories:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nDid you choose to focus on any of these categories? If so, what have you done in order to pursue your interest?\nI wanted to focus mostly on social responsibility, as this pertains mostly to what I am interested in outside of academic contexts, and I feel I have learned a great deal about social contexts in Machine Learning. The in-class activities about bias and data collection strategies, as well as the bias replication study I did for a blog post, have showed me a lot of ways that machine learning technologies can be unfairly biased.\nI also wanted to grow in my math knowledge, having not taken a math class since high school, and I have (somewhat surprisingly) really enjoyed regaining my calculus knowledge and understanding equations we use in our programs."
  },
  {
    "objectID": "posts/Mid-Course/mid-course.html#reflecting-on-goals",
    "href": "posts/Mid-Course/mid-course.html#reflecting-on-goals",
    "title": "Instructions",
    "section": "Reflecting on Goals",
    "text": "Reflecting on Goals\nFor each of the categories below, replace the “[your response here]” cell with 1-2 paragraphs in which you reflect on the following questions:\n\nIn what ways are you on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what you are doing in order to meet it.\nIn what ways are you not on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what gap you see between where you are and your goal.\nIf there’s any context you want to share about how you are faring relative to your goals, please do!\n\n\nBlog Posts\nMy goal was to complete two-thirds of the blog posts, and as I have only completed one, I am definitely not on track with that goal. I think I overestimated the amount of time and energy I would have to spend on blog posts, especially when I am not planning on using machine learning or programming knowledge in my post-graduate career, and I would like to alter my goal to completing at least three blog posts in total. I would like to allocate more of my energy for this class toward my final project, where I can choose what topics interest me and can motivate myself to invest more energy in it.\n\n\nCourse Presence (Participation)\nI have attended all classes that I could and participated in my group warmu-up discussions. I will continue to come prepared with the warm-up each day and engage with my group in every class.\n\n\nProject\nI would like to continue learning about social biases in machine learning. Many methods we’ve studied have been effective in identifying disparities in pre-existing data related to various topics, and I would like to find an existing dataset we haven’t looked at and apply a machine learning algorithm to it to find and visualize social disparities.\n\n\nOther\nIs there anything else that you want to share with me about what you have learned, how you have participated, or what you have achieved in CSCI 0451?\n[your response here]\n\n\nUpdating Your Goals\nFrom your experience in CSCI 0451 and your other classes this semester, you may feel moved to make modifications to your goals. Are they still feasible? Too ambitious? Not ambitious enough? If you would like to revise any of your goals from your reflective goal-setting, you can do so below. For each goal you want to modify:\n\nClearly state what the goal was.\nClearly state how you’ve done on that goal so far.\nClearly state your proposed revised goal for the remainder of the course.\n\nMy goal for was to complete two thirds of the assigned blog posts. I am not nearly on track to do this, as I have completed one blog post with revision still to do. I am recognizing that work in all of my classes will only increase as the semester’s end approaches and I begin to start work on final projects for each class, so I would like to revise my goal to complete three total blog posts, which leaves two remaining for me to do in the second half of the semester."
  },
  {
    "objectID": "posts/Mid-Course/mid-course.html#grade-and-goals",
    "href": "posts/Mid-Course/mid-course.html#grade-and-goals",
    "title": "Instructions",
    "section": "Grade and Goals",
    "text": "Grade and Goals\nTake 15 minutes to look back on your responses in each of the sections above. Then, state the letter grade that you feel reflects your learning, participation, and achievement in CSCI 0451 so far, and contextualize it against some of the soundbytes below.\n\nWhat a Grade Sounds Like\nAn A sounds like:\n\n“I am very proud of my time in this course.”\n“I have grown significantly in multiple ways that matter to me.”\n“I am ready to take the theory, techniques, and ideas of this course into my future classes, projects, hobbies, or career.”\n\nA B sounds like:\n\n“I had some opportunities to learn more, overall I feel good about my time in this course.”\n“I am able to explain some new things or achieve new tasks.”\n“I can see a few ideas from this course that will be relevant for my future classes, projects, hobbies, or career.”\n\nA C sounds like:\n\n“I often made a good effort, but I missed many opportunities to get more out of my time in this course.”\n“I might be able to complete some new tasks related to the course content, but only with significant further guidance.”\n“I don’t see any ways to take the contents of this course into my future classes, projects, hobbies, or career.”\n\nYou might find that some of these soundbytes resonate and other’s don’t! Take some time, see what feels right, and don’t be afraid to celebrate your achievements.\n\nUpon reflection, I feel that my learning, participation, and achievement in CSCI 0451 (so far) are best reflected by a grade of B\n\n\nA way in which I resonate with the soundbytes for that grade above is… I definitely feel good overall about what I have learned and achieved in this course, even if there are not many physical products of my work to attest to this. Going into the class, I knew it would be challenging material and challenging to motivate myself to learn all I can because this is my last semester as a CS student, but I am happy with how much I have mentally engaged with the material and with the topics in lectures. I have appreciated the emphasis on uses of machine learning in social contexts, rather than just learning different algorithms with no broader context. I am confident that this part of the class, which emphasizes bias, prejudice, and social disparity, will be useful to me outside the context of this class. I have also grown a lot in my math knowledge and will continue to do so throughout the remainder of the course. I can confidently say I can achieve new tasks that I was not able to before this class. While I could have expanded my learning with more blog posts and work outside of class, I know I have learned a great deal that I can take with me and use in my personal life outside of Midd."
  },
  {
    "objectID": "posts/Mid-Course/mid-course.html#optional-how-to-improve",
    "href": "posts/Mid-Course/mid-course.html#optional-how-to-improve",
    "title": "Instructions",
    "section": "(Optional:) How to Improve?",
    "text": "(Optional:) How to Improve?\nYou may feel disappointed by your reflection. Sometimes we don’t achieve all our goals – it happens and it’s normal! If you are feeling disappointed by how you’ve learned, participated, or achieved in CSCI 0451, then feel free to write something about that below. Feel free to just write your feelings. If you have ideas for how to move forward, include those too! We’ll talk.\n[your response here]"
  },
  {
    "objectID": "LinearModels_Perceptron_Torch.html",
    "href": "LinearModels_Perceptron_Torch.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "import torch\n\ntorch.manual_seed(1234)\n\ndef perceptron_data(n_points = 300, noise = 0.2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,2))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # convert y from {0, 1} to {-1, 1}\n    y = 2*y - 1\n\n    return X, y\n\nX, y = perceptron_data(n_points = 300, noise = 0.2)\n\n\nimport torch\n\nclass LinearModel:\n\n    def __init__(self):\n        self.w = None \n\n    def score(self, X):\n        \"\"\"\n        Compute the scores for each data point in the feature matrix X. \n        The formula for the ith entry of s is s[i] = &lt;self.w, x[i]&gt;. \n\n        If self.w currently has value None, then it is necessary to first initialize self.w to a random value. \n\n        ARGUMENTS: \n            X, torch.Tensor: the feature matrix. X.size() == (n, p), \n            where n is the number of data points and p is the \n            number of features. This implementation always assumes \n            that the final column of X is a constant column of 1s. \n\n        RETURNS: \n            s torch.Tensor: vector of scores. s.size() = (n,)\n        \"\"\"\n        if self.w is None: \n            self.w = torch.rand((X.size()[1]))\n\n        # your computation here: compute the vector of scores s\n        pass \n\n    def predict(self, X):\n        \"\"\"\n        Compute the predictions for each data point in the feature matrix X. The prediction for the ith data point is either 0 or 1. \n\n        ARGUMENTS: \n            X, torch.Tensor: the feature matrix. X.size() == (n, p), \n            where n is the number of data points and p is the \n            number of features. This implementation always assumes \n            that the final column of X is a constant column of 1s. \n\n        RETURNS: \n            y_hat, torch.Tensor: vector predictions in {0.0, 1.0}. y_hat.size() = (n,)\n        \"\"\"\n        pass \n\nclass Perceptron(LinearModel):\n\n    def loss(self, X, y):\n        \"\"\"\n        Compute the misclassification rate. A point i is classified correctly if it holds that s_i*y_i_ &gt; 0, where y_i_ is the *modified label* that has values in {-1, 1} (rather than {0, 1}). \n\n        ARGUMENTS: \n            X, torch.Tensor: the feature matrix. X.size() == (n, p), \n            where n is the number of data points and p is the \n            number of features. This implementation always assumes \n            that the final column of X is a constant column of 1s. \n\n            y, torch.Tensor: the target vector.  y.size() = (n,). The possible labels for y are {0, 1}\n        \n        HINT: In order to use the math formulas in the lecture, you are going to need to construct a modified set of targets and predictions that have entries in {-1, 1} -- otherwise none of the formulas will work right! An easy to to make this conversion is: \n        \n        y_ = 2*y - 1\n        \"\"\"\n\n        # replace with your implementation\n        pass\n\n    def grad(self, X, y):\n        pass \n\nclass PerceptronOptimizer:\n\n    def __init__(self, model):\n        self.model = model \n    \n    def step(self, X, y):\n        \"\"\"\n        Compute one step of the perceptron update using the feature matrix X \n        and target vector y. \n        \"\"\"\n        pass"
  },
  {
    "objectID": "Convexity-Warmup.html",
    "href": "Convexity-Warmup.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\n# Generate values for z\nz_values = np.linspace(-1, 1, 100)\n\n# Calculate sigmoid values\nsigmoid_values = sigmoid(z_values)\n\n# Plot sigmoid function\nplt.plot(z_values, sigmoid_values, label='Sigmoid Function')\nplt.title('Sigmoid Function')\nplt.xlabel('z')\nplt.ylabel('sigma(z)')\nplt.grid(True)\nplt.legend()"
  },
  {
    "objectID": "mid-course.html",
    "href": "mid-course.html",
    "title": "Instructions",
    "section": "",
    "text": "Download this notebook\nOpen the notebook in an editor of your choice (I recommend either VSCode or JupyterLab).\nDelete the first two cells of the notebook (i.e. this one and the raw cell above).\nBriefly review the goals you set for yourself in our goal-setting activity at the beginning of the course. You can find your goals on Canvas.\nIn the The Data section, replace the blanks with brief responses.\nIn the What You Learned and Reflecting on Goals sections, write down your reflections on your learning, achievement, and presence in CSCI 0451 in the provided markdown cells.\nTake some time to reflect on your responses so far. When you’re ready, review the soundbytes describing letter grades.\nTake some time to reflect on your responses so far. When you’re ready, propose the letter grade that you feel best reflects your learning, participation, and achievement in CSCI 0451 so far.\nOptionally, respond to the last prompt with some thoughts on how the semester is going and what we might do to help you meet your goals for the course.\nSubmit the notebook as a PDF on Canvas.\n\nWe’ll discuss your reflection and your proposed letter grade during our end-of-semester conference.\nThere are lots of ways to render Jupyter notebooks as PDFs. The simplest way is to run this at the command line, after you’ve navigated to the location of the notebook:\njupyter nbconvert --to pdf mid-course.ipynb"
  },
  {
    "objectID": "mid-course.html#the-data",
    "href": "mid-course.html#the-data",
    "title": "Instructions",
    "section": "The Data",
    "text": "The Data\nIn this section I’ll ask you to fill in some data. You don’t have to give precise numbers – approximate, conversational responses are fine. For example, when I ask “how often have you attended class,” good answers include “almost always,” “I’ve missed three times,” “about 75% of the time,” “not as often as I want,” etc.\n\nPresence in Class\n\nHow often have you attended class? (e.g. “almost always,” “I missed three times,” etc.) I have missed a few times, only when I had other appointments\nHow often have you taken notes on the core readings ahead of the class period? never\nHow often have you been prepared to present the daily warm-up exercise to your team, even if you weren’t actually called? pretty much every day except the day I was called to present\nHow many times have you actually presented the daily warm-up to your team? 1\nHow many times have you asked your team for help while presenting the daily warm-up? 1\nHow often have you learned something new from a teammate’s presentation of the daily warm-up? most days\nHow often have you helped a teammate during the daily warm-up presentation? quite often, when help is needed\n\n\n\nPresence Outside of Class\n\nHow often have you attended Student Hours or Peer Help? once\nHow often have you asked for or received help from your fellow students? several times\nHave you been regularly participating in a study group outside class? no\nHow often have you posted questions or answers in Slack? have asked direct questions\n\n\n\nAssignments and Effort\n\nHow many blog posts have you submitted? one\nHow many of your submitted blog posts are at each of the following feedback stages?\n\nE: No revisions suggested: ____\nM: Revisions useful: ____\nR: Revisions encouraged: 1\nN: Incomplete: ____\n\nRoughly how many hours per week have you spent on this course outside of class? 4"
  },
  {
    "objectID": "mid-course.html#what-youve-learned",
    "href": "mid-course.html#what-youve-learned",
    "title": "Instructions",
    "section": "What You’ve Learned",
    "text": "What You’ve Learned\nAt the beginning of the course, you may have expressed an interest in focusing a little extra on one or two of the following four categories:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nDid you choose to focus on any of these categories? If so, what have you done in order to pursue your interest?\nI wanted to focus mostly on social responsibility, as this pertains mostly to what I am interested in outside of academic contexts, and I feel I have learned a great deal about social contexts in Machine Learning. The in-class activities about bias and data collection strategies, as well as the bias replication study I did for a blog post, have showed me a lot of ways that machine learning technologies can be unfairly biased.\nI also wanted to grow in my math knowledge, having not taken a math class since high school, and I have (somewhat surprisingly) really enjoyed regaining my calculus knowledge and understanding equations we use in our programs."
  },
  {
    "objectID": "mid-course.html#reflecting-on-goals",
    "href": "mid-course.html#reflecting-on-goals",
    "title": "Instructions",
    "section": "Reflecting on Goals",
    "text": "Reflecting on Goals\nFor each of the categories below, replace the “[your response here]” cell with 1-2 paragraphs in which you reflect on the following questions:\n\nIn what ways are you on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what you are doing in order to meet it.\nIn what ways are you not on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what gap you see between where you are and your goal.\nIf there’s any context you want to share about how you are faring relative to your goals, please do!\n\n\nBlog Posts\nMy goal was to complete two-thirds of the blog posts, and as I have only completed one, I am definitely not on track with that goal. I think I overestimated the amount of time and energy I would have to spend on blog posts, especially when I am not planning on using machine learning or programming knowledge in my post-graduate career, and I would like to alter my goal to completing at least three blog posts in total. I would like to allocate more of my energy for this class toward my final project, where I can choose what topics interest me and can motivate myself to invest more energy in it.\n\n\nCourse Presence (Participation)\nI have attended all classes that I could and participated in my group warmu-up discussions. I will continue to come prepared with the warm-up each day and engage with my group in every class.\n\n\nProject\nI would like to continue learning about social biases in machine learning. Many methods we’ve studied have been effective in identifying disparities in pre-existing data related to various topics, and I would like to find an existing dataset we haven’t looked at and apply a machine learning algorithm to it to find and visualize social disparities.\n\n\nOther\nIs there anything else that you want to share with me about what you have learned, how you have participated, or what you have achieved in CSCI 0451?\n[your response here]\n\n\nUpdating Your Goals\nFrom your experience in CSCI 0451 and your other classes this semester, you may feel moved to make modifications to your goals. Are they still feasible? Too ambitious? Not ambitious enough? If you would like to revise any of your goals from your reflective goal-setting, you can do so below. For each goal you want to modify:\n\nClearly state what the goal was.\nClearly state how you’ve done on that goal so far.\nClearly state your proposed revised goal for the remainder of the course.\n\nMy goal for was to complete two thirds of the assigned blog posts. I am not nearly on track to do this, as I have completed one blog post with revision still to do. I am recognizing that work in all of my classes will only increase as the semester’s end approaches and I begin to start work on final projects for each class, so I would like to revise my goal to complete three total blog posts, which leaves two remaining for me to do in the second half of the semester."
  },
  {
    "objectID": "mid-course.html#grade-and-goals",
    "href": "mid-course.html#grade-and-goals",
    "title": "Instructions",
    "section": "Grade and Goals",
    "text": "Grade and Goals\nTake 15 minutes to look back on your responses in each of the sections above. Then, state the letter grade that you feel reflects your learning, participation, and achievement in CSCI 0451 so far, and contextualize it against some of the soundbytes below.\n\nWhat a Grade Sounds Like\nAn A sounds like:\n\n“I am very proud of my time in this course.”\n“I have grown significantly in multiple ways that matter to me.”\n“I am ready to take the theory, techniques, and ideas of this course into my future classes, projects, hobbies, or career.”\n\nA B sounds like:\n\n“I had some opportunities to learn more, overall I feel good about my time in this course.”\n“I am able to explain some new things or achieve new tasks.”\n“I can see a few ideas from this course that will be relevant for my future classes, projects, hobbies, or career.”\n\nA C sounds like:\n\n“I often made a good effort, but I missed many opportunities to get more out of my time in this course.”\n“I might be able to complete some new tasks related to the course content, but only with significant further guidance.”\n“I don’t see any ways to take the contents of this course into my future classes, projects, hobbies, or career.”\n\nYou might find that some of these soundbytes resonate and other’s don’t! Take some time, see what feels right, and don’t be afraid to celebrate your achievements.\n\nUpon reflection, I feel that my learning, participation, and achievement in CSCI 0451 (so far) are best reflected by a grade of B\n\n\nA way in which I resonate with the soundbytes for that grade above is… I definitely feel good overall about what I have learned and achieved in this course, even if there are not many physical products of my work to attest to this. Going into the class, I knew it would be challenging material and challenging to motivate myself to learn all I can because this is my last semester as a CS student, but I am happy with how much I have mentally engaged with the material and with the topics in lectures. I have appreciated the emphasis on uses of machine learning in social contexts, rather than just learning different algorithms with no broader context. I am confident that this part of the class, which emphasizes bias, prejudice, and social disparity, will be useful to me outside the context of this class. I have also grown a lot in my math knowledge and will continue to do so throughout the remainder of the course. I can confidently say I can achieve new tasks that I was not able to before this class. While I could have expanded my learning with more blog posts and work outside of class, I know I have learned a great deal that I can take with me and use in my personal life outside of Midd."
  },
  {
    "objectID": "mid-course.html#optional-how-to-improve",
    "href": "mid-course.html#optional-how-to-improve",
    "title": "Instructions",
    "section": "(Optional:) How to Improve?",
    "text": "(Optional:) How to Improve?\nYou may feel disappointed by your reflection. Sometimes we don’t achieve all our goals – it happens and it’s normal! If you are feeling disappointed by how you’ve learned, participated, or achieved in CSCI 0451, then feel free to write something about that below. Feel free to just write your feelings. If you have ideas for how to move forward, include those too! We’ll talk.\n[your response here]"
  },
  {
    "objectID": "posts/bias-replication-post/Bias-Replication.html#finding-disparities-in-risk-score-percentile-by-mean-chronic-illnesses",
    "href": "posts/bias-replication-post/Bias-Replication.html#finding-disparities-in-risk-score-percentile-by-mean-chronic-illnesses",
    "title": "Bias Replication Study",
    "section": "",
    "text": "In this figure we plot risk score percentile by the mean number of chronic illnesses within each percentile, with data points separated by race. Here we see a clear difference between races, with white patients more likely to be given a higher risk score than Black patients with the same number of chronic illnesses. If Patient A were white and Patient B were Black, and both patients had the same chronic illnesses, Patient A would be significantly more likely to have a higher risk score and be referred to a high-risk care management program.\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Calculate risk score percentiles\ndf['risk_score_percentile'] = df['risk_score_t'].rank(pct=True).round(2)\n\n\n# Calculate mean number of gagne_sum_t within each risk score percentile\nmean_gagne_per_percentile = df.groupby(['risk_score_percentile', 'race'])['gagne_sum_t'].mean().reset_index()\n\n\n# Plot\nsns.scatterplot(data=mean_gagne_per_percentile, x='gagne_sum_t', y='risk_score_percentile', hue='race', style='race')\nplt.xlabel('Mean Chronic Illnesses')\nplt.ylabel('Risk Score Percentile')\nplt.xlim(0,8)\nplt.show()"
  },
  {
    "objectID": "posts/bias-replication-post/Bias-Replication.html#racial-disparity-in-medical-expenses-by-chronic-illnesses-and-risk-score",
    "href": "posts/bias-replication-post/Bias-Replication.html#racial-disparity-in-medical-expenses-by-chronic-illnesses-and-risk-score",
    "title": "Bias Replication Study",
    "section": "",
    "text": "Here we explore differences in cost incurred by Black and white patients with various risk scores and various numbers of chronic illnesses. These figures suggest that, for Black patients, as risk score and number of chronic illnesses increase, medical expenditures increase at a higher rate than that of white patients. For lower risk scores and chronic illness counts, white patients seem to have slightly higher medical costs than for Black patients, but it appears as though Black patients are penalized more severely for having more illnesses and being of higher risk.\n\n#group data with risk score percentile and cost\ndf_cost = df.groupby(['risk_score_percentile', 'race'])['cost_t'].mean().reset_index()\n\n#group data with number of chronic illnesses and cost\ndf_cost2 = df.groupby(['gagne_sum_t', 'race'])['cost_t'].mean().reset_index()\n\n\nfig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 5))\n\n#plot cost by percentile risk score\np1 = sns.scatterplot(data=df_cost, x='risk_score_percentile', y='cost_t', hue='race', style='race', ax = ax1)\np1.set_xlabel('Percentile Risk Score')\np1.set_ylabel('Total Medical Expenditures')\nplt.gca().semilogy()\n\n#plot cost by number of chronic illnesses\np2 = sns.scatterplot(data=df_cost2, x='gagne_sum_t', y='cost_t', hue='race', style='race', ax = ax2)\np2.set_xlabel('Number of Chronic Illnesses')\np2.set_ylabel('Total Medical Expenditures')\nplt.gca().semilogy()\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\n\n# Calculate the percentage of patients with 5 or fewer chronic conditions\npercentage = (len(df[df['gagne_sum_t'] &lt;= 5]) / len(df)) * 100\n\n# 95.53952115447689 - choice to use patients with 5 or fewer chronic conditions makes sense, \n# as 96% of patients have 5 or fewer chronic conditions.\n\n# Eliminate subjects with 0 cost, perform log function on cost column\ndf = df[df['cost_t'] &gt; 0]\ndf['log_cost'] = df['cost_t'].apply(lambda x: np.log(x))\n\n# Create a dummy column for the race variable\ndf['race_encoded'] = pd.get_dummies(df['race'], drop_first=True)\n\n# Separate the data into predictor variables (X) and target variable (y)\nX = df[['race_encoded', 'gagne_sum_t']]\ny = df['log_cost']"
  },
  {
    "objectID": "posts/bias-replication-post/Bias-Replication.html#logistic-regression-for-medical-costs-given-number-of-chronic-illnesses.",
    "href": "posts/bias-replication-post/Bias-Replication.html#logistic-regression-for-medical-costs-given-number-of-chronic-illnesses.",
    "title": "Bias Replication Study",
    "section": "",
    "text": "from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Function to add polynomial features\ndef add_polynomial_features(X, degree):\n    X_ = X.copy()\n    for j in range(1, degree):\n        X_[f\"poly_{j}\"] = X_[\"gagne_sum_t\"]**j\n    return X_\n\n# Create different degrees of polynomial features and compute cross-validation scores\ndegrees = range(1, 15)\nscores = []\n\nfor degree in degrees:\n    # Add polynomial features\n    X_poly = add_polynomial_features(X, degree)\n    \n    # Perform cross-validation with linear regression\n    lr = LinearRegression()\n    cv_score = cross_val_score(lr, X_poly, y, cv=5).mean()\n    scores.append(cv_score)\n\n# Determine the optimal degree based on cross-validation scores\noptimal_degree = degrees[np.argmax(scores)]\nprint(\"Optimal degree based on cross-validation:\", optimal_degree)\n\n# Construct data with the optimal number of polynomial features\nX_poly_optimal = add_polynomial_features(X, optimal_degree)\n\n# Fit the final linear regression model\nlr_final = LinearRegression()\nlr_final.fit(X_poly_optimal, y)\n\n# Get coefficients of the linear regression model\ncoefficients = lr_final.coef_\n\n\n# Identify the coefficient corresponding to the Black race\nwb = coefficients[-1]\nprint(\"w_b: \", wb)\n\n# Compute e^wb\ne_wb = np.exp(wb)\nprint(\"e^w_b: \", e_wb)\n\nOptimal degree based on cross-validation: 10\nw_b:  9.390071033164823e-08\ne^w_b:  1.0000000939007148\n\n\nThis linear regression model worked best with cross validation on 10 polynomial degrees. After fitting the final linear regression model, the value I received for e^(w_b) was 1.0000000939007148, indicating that a Black patient pays slightly over 100% of the cost that an equally sick white patient must pay."
  },
  {
    "objectID": "posts/bias-replication-post/Bias-Replication.html#discussion",
    "href": "posts/bias-replication-post/Bias-Replication.html#discussion",
    "title": "Bias Replication Study",
    "section": "",
    "text": "The above plots give visual representations of racial disparities in medical care, and the logistic regression models slight disparities in cost incurred by equally sick patients. However, while this value of slightly more than 100% may seem like only a minor difference, it could be suggested that the value extracted from the regression does not account for the kinds of disparities that are present. As we see in the Medical Expenditure Plots above, as Risk Score Percentile and Number of Chronic Illnesses increase, so does the different in cost between Black and white patients. While white patients might pay as much as or more than Black patients for lower-risk, less severe conditions, Black patients are financially penalized as their conditions become more severe, and the logistic regression does not account for this idea. The plots clearly model differences in the way Black and white patients are treated, specifically of Barocas et al’s discrimination criterion of “outcome frequency given score value”. If these observations were “fair”, statistics for Black and white patients would be about equal, given that their medical conditions are identical. However, we do see clear outliers and differing trends between patients of different race but identical medical conditions, scoring Black patients at significantly lower risk than equally sick white patients and with high-risk Black patients incurring significantly higher medical costs than equally sick white patients."
  },
  {
    "objectID": "posts/bias-replication-post/Bias-Replication.html#references",
    "href": "posts/bias-replication-post/Bias-Replication.html#references",
    "title": "Bias Replication Study",
    "section": "",
    "text": "Barocas, Solon, Moritz Hardt, and Arvind Narayanan. 2023. Fairness and Machine Learning: Limitations and Opportunities. Cambridge, Massachusetts: The MIT Press.\nObermeyer, Ziad, Brian Powers, Christine Vogeli, and Sendhil Mullainathan. 2019. “Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations.” Science 366 (6464): 447–53. https://doi.org/10.1126/science.aax2342."
  },
  {
    "objectID": "convolutional-kernel.html",
    "href": "convolutional-kernel.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "import urllib.request\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport torch\nimport numpy as np\n\ndef read_image(url):\n    urllib.request.urlretrieve(url, \"maru.png\")\n    img = Image.open(\"maru.png\")\n    return torch.tensor(np.array(img)/255).float()\n\nurl = \"https://github.com/middlebury-csci-0451/CSCI-0451-s24/blob/main/assets/img/figs/maru.png?raw=true\"\n\nimg = read_image(url)\n\ndef to_greyscale(im):\n    v = torch.tensor([0.2989, 0.5870, 0.1140])\n    return 1 - img[:,:,:3]@v\n\nimg = to_greyscale(img)\n\nplt.imshow(img, cmap = \"Greys\")\nno_ax = plt.gca().axis(\"off\")\n\n: \n\n\n\ndef kernel_convolution(X, K):\n    # Get dimensions of input image and kernel\n    img_height, img_width = X.shape\n    kernel_size = K.shape[0]\n    \n    # Pad the input image symmetrically to handle edges\n    pad_width = kernel_size // 2\n    X_padded = torch.nn.functional.pad(X, (pad_width, pad_width, pad_width, pad_width), mode='constant', value=0)\n    \n    # Initialize output feature map\n    output_height = img_height\n    output_width = img_width\n    output = torch.zeros((output_height, output_width))\n    \n    # Perform convolution\n    for i in range(output_height):\n        for j in range(output_width):\n            # Extract the local region of the image\n            local_region = X_padded[i:i+kernel_size, j:j+kernel_size]\n            # Perform element-wise multiplication with the kernel and sum\n            output[i, j] = torch.sum(local_region * K)\n    \n    return output\n\n\nkernel = torch.tensor([[-1, -1, -1], [-1,  8, -1], [-1, -1, -1]])\n\nconvd = kernel_convolution(img, kernel)\n\nplt.imshow(convd, cmap = \"Greys\", vmin = 0, vmax = 0.1)\nplt.gca().axis(\"off\")"
  },
  {
    "objectID": "posts/limits-to-quantitative/limits-to-quantitative-approach.html",
    "href": "posts/limits-to-quantitative/limits-to-quantitative-approach.html",
    "title": "Limits to the Quantitative Approach to Bias and Fairness",
    "section": "",
    "text": "In his 2022 lecture, “Limits of the quantitative approach to discrimination,” Arvind Narayanan discusses significant drawbacks in attempts to quantify bias in machine learning and data, arguing that they “do more harm than good.” He opens his speech declaring the intention to “help people see past the myth that numbers don’t lie,” and delves into an analysis of ProPublica’s Machine Bias investigation of Florida’s Broward County criminal risk prediction data, which exposed that Black defendants were nearly twice as likely as white defendants to be falsely flagged as potential reoffenders.\nThis study reflects ideas of quantitative fairness discussed by Barocas, Hardt, and Narayanan (2023), with error rate parity as a candidate for a fairness measure and Black and white defendants as groups to be classified. While error rates between groups might be similar, the differences in types of errors made between groups and the harmful effects of these errors must be analyzed, as the effect on an individual of being falsely flagged as a reoffender can be far more harmful to a person than being falsely flagged as a non-reoffender. Narayanan draws attention to the subjectivity involved in scientists’ “tentative conclusions in the face of incomplete evidence” (Narayanan 2022). As an example, he points to statements made about a lack of evidence on COVID vaccines’ effectiveness against variants: “no evidence of vaccine effectiveness against variants” vs. “no evidence that vaccines are less effective against variants”. These two statements appear to be very similar, but they hold very different implications. Scientists must consciously decide how to phrase these conclusions to the public, and often the way these conclusions are presented to the public reflect individual scientists’ biases, though they are often accepted as reliable without question.\nThis subjectivity can also be seen in null hypotheses. Narayanan points out that the virtually universal default assumption in science is that there is no discrimination, which allocates the “burden of proof” to those who either experience discrimination or believe that there could be discrimination involved (Narayanan 2022). In reality, though, the null hypothesis could just as easily be that there is discrimination, in which case the burden of proof would fall on those believing there is no discrimination. Narayanan also points to issues with the data itself. Datasets are most often snapshots, representing a single point in time, and do not represent the fuller picture of possible discriminatory history for any given subject. This leads scientists to neglect the possible conclusion that disparities in data are due to discrimination, especially since most of the organizations in charge of collecting and releasing the data make discrete decisions that affect the conclusions that are drawn about the data.\nNarayanan names previous discrimination studies that compared subjects that were completely identical except for race. While these studies found significant differences in results between white subjects and Black subjects, Narayanan points out that controlling every single variable except race essentially discounts the possibility that other factors, such as neighborhood or wardrobe, could be involved in discrimination. As Narayanan powerfully phrases this idea, researchers “end up controlling for the attributes that together constitute the social construct of race” (Narayanan 2022). This way, employers or other powerful groups can make decisions based on race-related factors without explicitly naming race as a factor, “explaining away” discriminatory attitudes.\nBarocas, Hardt, and Narayanan (2023) explain this idea with independence between variables. As they point out, though, independence is not always Naming corporations such as Uber as participants in corrupt research, Narayanan demonstrates the harmful effects that this narrow data has on real people. He continues to warn that, because quantitative research is widely viewed as “objective”, many people in power have begun to adopt these deficient ideas, distributing “evidence” with narrow definitions of discrimination.\nNarayanan points to faulty AI tools that are used for hiring, which consider starkly irrelevant factors and give each candidate a score, at best equivalent to the result of a random number generator. While one would expect regulators, such as the Equal Employment Opportunity Commission, to catch these blatant misjudgments, the only measure of unfairness they recognize is disparate impact – concrete quantitative evidence that people of different races, genders, etc. are being accepted at different rates. Narayanan points out that this measure is amenable to quantitative research on snapshot datasets, enabling incomplete discrimination research to continue unquestioned.\nTo conclude his speech, Narayanan advises quantitative researchers to go deeper. Rather than tailoring research questions to the available data, he implores people to take the extra time to collect, analyze, and interrogate timely, evocative data that transcends a simple snapshot. He advises researchers to spend time with and develop empathy for their research subjects, especially those harmed by discrimination, in order to best serve those affected. Narayanan suggests a future in which quantitative data can be examined alongside various other forms of critical evidence, recognized as a small part, but not all, of the big picture.\nAdding to this discussion on the efficacy and integrity of quantitative research, Denison, Bevan, and Jeanes (2021) conducted a narrative analysis of quantitative evidence of discrimination, specifically of LGBTQIA+ athletes in their respective sports, by examining the work of several researchers. Citing Brackenridge et al. (2008), they point out that the observed lack of hard evidence of discrimination makes it easier to ignore the problems faced by those affected by unfair bias. Aiming to shed light on the available quantitative data surrounding LGBTQIA+ athletes, they describe the work of Cunningham and Pickett (2018) and MacDonald (2019), through which over a quarter of surveyed male athletes reported discomfort with the idea of a homosexual teammate, with a higher percentage expressing discomfort with a transgender teammate. Similar studies were conducted from 2011 through 2020, demonstrating that a majority of male athletes, even those who reportedly supported same-sex marriage, regularly used homophobic language with their teammates. Believing their language to be harmless, as there were no openly gay players on their teams, these athletes disregarded the possibility that their exhibited attitudes might prevent a queer player from feeling comfortable enough to share their identity with their team.\nContinuing to report on studies surveying perspectives of LGBTQIA+ athletes, Denison, Bevan, and Jeanes (2021) reference the international study performed by Menzel, Braumuller, and Hartmann-Tews (2019) that collected self-reported data from LGBTQIA+ athletes from all EU countries. As Narayanan emphasizes, it is crucial in discrimination studies to hear from those negatively affected by bias. While many subjects of previously mentioned studies may not have believed that they were actively contributing to a harmful environment, the queer athletes that were surveyed provide compelling responses alluding to the existence of discrimination in sports. With over 5,500 LBGTQIA+ athletes completing their survey, Menzel, Braumuller, and Hartmann-Tews (2019) reported that 82% of participants had recently witnessed homophobic or transphobic behavior, and that 90% believed homophobia and transphobia to be current problems in sports. Similarly, Denison and Kitchen (2015) found that, from their pool of lesbian, gay, and bisexual subjects from six countries, 82% had experienced homophobia in sports. 73% of participants in this study also reported belief that it was not safe for queer youth to come out to their sports teams.\nAs our culture has evolved over the past decades, blatant disrespect of specific subpopulations has become increasingly denounced. As social attitudes appear to be heading toward inclusivity on paper, with fewer people feeling comfortable to report discriminatory opinions, it becomes ever more difficult to provide quantitative evidence of discrimination; people can disguise their true feelings and explain away their discriminatory practices, such as using homophobic slurs. While Denison, Bevan, and Jeanes (2021) provide compelling self-reported data alluding to discrimination, the subjectivity involved in the collection of these responses may not be accepted with the finality that a more seemingly objective, quantitative report might be.\nFor example, Brackenridge et al. (2008) report hesitancy on the part of sports managers and coaches to make any effort to mitigate potential harm due to the lack of “hard data/evidence”, demonstrating how much power quantitative research holds over society, even when there is plenty of self-reported discrimination being experienced. As Narayanan warns us to view quantitative data as only part of the picture, rather than the ultimate truth, the seemingly apathetic responses received from sports management demonstrate that instead of putting all faith into quantitative data, research should focus more on the experiences of individuals harmed by discriminatory attitudes.\nNarayanan’s points highlight the serious overestimation of quantitative data. When people but blind faith into what they believe to be concrete evidence, it allows for the discretion of quantitative researchers to determine the fate of populations who are harmed by unquantifiable but real discrimination. I agree that quantitative research should be more interrogative and critical, aiming to expose the truth rather than draw unfounded conclusions. Researchers should examine the reasons behind patterns in data and explore all possibilities beyond the surface of the data; if the null hypothesis were to be that discrimination is present, researchers could be motivated to find potential causes of harmful practices. I also agree that society should reallocate their faith in research, recognizing the limits of quantitative data and seeking out more holistic, personal modes of research. While quantitative data is an important part of scientific research and can reveal many important patterns, it does not constitute the whole, objective truth, and the research community as well as its audience should keep this in mind as they search for underlying causes.\n\n\n\n\nReferences\n\nBarocas, Solon, Moritz Hardt, and Arvind Narayanan. 2023. Fairness and Machine Learning: Limitations and Opportunities. Cambridge, Massachusetts: The MIT Press.\n\n\nBrackenridge, C., P. Aldred, A. Jarvis, I. Rivers, and K. Maddocks. 2008. “Literature Review of Sexual Orientation in Sport.” Sport England, 153.\n\n\nCunningham, G. B., and A. C. Pickett. 2018. “Trans Prejudice in Sport: Differences from LGB Prejudice, the Influence of Gender, and Changes over Time.” Sex Roles 78 (3-4): 220–27. https://doi.org/https://doi.org/10.1007/s11199-017-0791-6.\n\n\nDenison, E., N. Bevan, and R. Jeanes. 2021. “Reviewing Evidence of LGBTQ+ Discrimination and Exclusion in Sport.” Sport Management Review 24 (3): 389–409. https://doi.org/https://doi.org/10.1016/j.smr.2020.09.003.\n\n\nDenison, E., and A. Kitchen. 2015. “Out on the Fields. Bingham Cup Sydney 2014.” Australian Sports Commission, Nielsen Sport. https://doi.org/https://doi.org/10.26180/5e1e6059a7c0e.\n\n\nMacDonald, C. A. 2019. “Insert Name of Openly Gay Hockey Player Here - Attitudes Towards Homosexuality Among Canadian Male Major Midget AAA Ice Hockey Players.” Sociology of Sport Journal 35 (4): 347–57. https://doi.org/http://doi.org/10.1123/ssj.2017-0133.\n\n\nMenzel, T., B. Braumuller, and I. Hartmann-Tews. 2019. “The Relevance of Sexual Orientation and Gender Identity in Sport in Europe - Findings from the Outsport Survey.” German Sport University Cologne - Institute of Sociology and Gender.\n\n\nNarayanan, Arvind. 2022. “The Limits of the Quantitative Approach to Discrimination.” Speech."
  },
  {
    "objectID": "posts/limits-to-quantitative/limits-to-quantitative-approach.html#limits-to-the-quantitative-approach-to-bias-and-fairness",
    "href": "posts/limits-to-quantitative/limits-to-quantitative-approach.html#limits-to-the-quantitative-approach-to-bias-and-fairness",
    "title": "Limits to the quantitative approach to bias and fairness",
    "section": "Limits to the quantitative approach to bias and fairness",
    "text": "Limits to the quantitative approach to bias and fairness\nIn his 2022 lecture, “Limits of the quantitative approach to discrimination,” Arvind Narayanan discusses significant drawbacks in attempts to quantify bias in machine learning and data, arguing that they “do more harm than good”(@narayanan2022). He opens his speech declaring the intention to “help people see past the myth that numbers don’t lie” (@narayanan2022), and delves into an analysis of ProPublica’s Machine Bias investigation of Florida’s Broward County criminal risk prediction data, which exposed that Black defendants were nearly twice as likely as white defendants to be falsely flagged as potential reoffenders."
  },
  {
    "objectID": "logistic-regression.html",
    "href": "logistic-regression.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "%load_ext autoreload\n%autoreload 2\nfrom logistic import LogisticRegression, GradientDescentOptimizer"
  },
  {
    "objectID": "posts/logistic/logistic-regression.html",
    "href": "posts/logistic/logistic-regression.html",
    "title": "Implementing Logistic Regression",
    "section": "",
    "text": "%load_ext autoreload \n%autoreload 2\nfrom logistic import LogisticRegression, GradientDescentOptimizer\nimport torch\nfrom matplotlib import pyplot as plt\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload"
  },
  {
    "objectID": "posts/logistic/logistic-regression.html#experiment-1-vanilla-gradient-descent",
    "href": "posts/logistic/logistic-regression.html#experiment-1-vanilla-gradient-descent",
    "title": "Implementing Logistic Regression",
    "section": "Experiment 1: Vanilla Gradient Descent",
    "text": "Experiment 1: Vanilla Gradient Descent\nHere I implement Vanillla Gradient Descent, which involves a beta learning rate of 0. This erases the effect of Spicy Gradient Descent, using only one learning rate. The classification data I generate uses 2 dimensions and a noise level of 0.5. I fit the logistic regression model and gradient descent optimizer, define a vector that will track the loss, and train the model over 100 iterations with a learning rate of alpha=0.1.\n\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\nloss_vec = []\n\nX, y = classification_data(p_dims =2, noise = 0.5)\n\nfor _ in range(100):\n    \n    #keep track of loss over iterations\n    loss = LR.loss(X, y) \n    loss_vec.append(loss)\n\n    opt.step(X, y, alpha = 0.1, beta = 0.0)\n\nHere I define and call several plotting functions to demonstrate the results of the logistic regression model. plot_decision_boundary plots the data separated by the decision boundary with the final loss value, and plot_loss plots the loss vector over time.\n\ndef plot_decision_boundary():\n\n    # Plot the data points\n    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm', edgecolors='k', label='Data Points')\n\n    # Plot the decision boundary line\n    w = LR.w.detach().numpy()  # Convert weight tensor to numpy array\n    x_values = torch.linspace(X[:, 0].min(), X[:, 0].max(), 100)\n    y_values = -(w[0] * x_values + w[-1]) / w[1]  # Compute y values for the decision boundary line\n    plt.plot(x_values, y_values, color='black', linestyle='--', label='Decision Boundary')\n\n    plt.xlabel('x1')\n    plt.ylabel('x2')\n    plt.title(f'LR Decision Boundary: Loss = {loss_vec[-1]:.3f}')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n    \n#plot loss vector\ndef plot_loss(loss_vec):\n    plt.plot(torch.arange(1, len(loss_vec)+1), loss_vec, color = \"black\")\n    labs = plt.gca().set(xlabel = \"Number of gradient descent iterations\", ylabel = \"Loss (binary cross entropy)\")\n\n\nplot_decision_boundary()\nplot_loss(loss_vec)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs can be seen from these plots, the loss continually decreases, from about 0.65 to 0.38, reaching this final value only after all 100 iterations. The decision boundary shows the separation of the two-dimensional data points, appearing to correctly classify most data points."
  },
  {
    "objectID": "posts/logistic/logistic-regression.html#experiment-2-benefits-of-momentum",
    "href": "posts/logistic/logistic-regression.html#experiment-2-benefits-of-momentum",
    "title": "Implementing Logistic Regression",
    "section": "Experiment 2: Benefits of Momentum",
    "text": "Experiment 2: Benefits of Momentum\nHere I will use the same data to show that adding a positive beta learning rate, representing momentum, causes the weight vector to converge after fewer iterations than with Vanilla Gradient Descent. This can be shown by plotting the loss vector and observing when the decrease in loss slows down.\n\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\nloss_vec = []\n\nfor _ in range(100):\n    \n    loss = LR.loss(X, y) \n    loss_vec.append(loss)\n    # add other stuff to e.g. keep track of the loss over time. \n    opt.step(X, y, alpha = 0.1, beta = 0.9)\n\nplot_loss(loss_vec)\n\n\n\n\n\n\n\n\nThis loss plot shows that the “elbow” of the curve lies around 30 iterations, after which the decrease is much more gradual. The most drastic decrease happens much earlier than the Vanilla curve above, after about 15 iterations. As shown with the following print statements, the loss stops significantly decreasing around 40 iterations.\n\nprint(\"Loss decrease after 40 iterations: \", float(loss_vec[0]-loss_vec[39]))\nprint(\"Loss decrease from 40 to 100 iterations: \", float(loss_vec[40]-loss_vec[99]))\n\nLoss decrease after 40 iterations:  0.41942232847213745\nLoss decrease from 40 to 100 iterations:  0.020639359951019287\n\n\nWith a high momentum value, the same alpha learning rate, and the same dataset, the weight vector converges to its final values much sooner than with Vanilla Gradient Descent. Momentum would allow us to train the model over fewer iterations, requiring less time and memory."
  },
  {
    "objectID": "posts/logistic/logistic-regression.html#experiment-3-overfitting",
    "href": "posts/logistic/logistic-regression.html#experiment-3-overfitting",
    "title": "Implementing Logistic Regression",
    "section": "Experiment 3: Overfitting",
    "text": "Experiment 3: Overfitting\nIn this experiment, I will show how overfitting the model to the training data yields low test accuracy. By training the model on a train set until receiving a very high train accuracy, the model does not generalize as well to test data, because it is fit too closely to the specific data that the model is trained on.\nHere I generate two data sets: train and test. Both sets have the same parameters: four points and 20 dimensions. I will fit the LR model to the train set until receiving a train accuracy of 100%, and then I will test the model on the test data.\n\nfrom sklearn.metrics import accuracy_score\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nX_train, y_train = classification_data(p_dims = 20, n_points = 4, noise = 0.4)\nX_test, y_test = classification_data(p_dims =20, n_points = 4, noise = 0.4)\n\nloss_vec = []\nloss = LR.loss(X_train, y_train) \nloss_vec.append(loss)\nwhile loss &gt; 0.001:\n    #keep track of the loss over time. \n    loss = LR.loss(X_train, y_train) \n    loss_vec.append(loss)\n    \n    opt.step(X_train, y_train, alpha = 0.01, beta = 0.2)\n\n#predict y values on train data and calculate train accuracy\ny_train_pred = LR.predict(X_train)\ntrain_accuracy = accuracy_score(y_train, y_train_pred)\nprint(f\"Train accuracy: {train_accuracy * 100}%\")\n\nTrain accuracy: 100.0%\n\n\n\nplot_loss(loss_vec)\n\n\n\n\n\n\n\n\nWith 3 data points and 10 dimensions, the model trained until the loss reached around 0 and the accuracy on the train accuracy was 100%. The model continued training for over 60,000 iterations, but the loss reached a low value quite early on. As can be seen below, though the training accuracy was 100%, the test accuracy was 75%. Because the model trained on the training set for 60,000 iterations, the train set performed better than the test set, indicating overfitting.\n\ny_test_pred = LR.predict(X_test)\ntest_accuracy = accuracy_score(y_test, y_test_pred)\nprint(f\"Test accuracy: {test_accuracy * 100}%\")\n\nTest accuracy: 75.0%"
  },
  {
    "objectID": "posts/music-classification/DeepMusicGenreClassification.html",
    "href": "posts/music-classification/DeepMusicGenreClassification.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "import pandas as pd\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/tcc_ceds_music.csv\"\ndf = pd.read_csv(url)\nengineered_features = ['dating', 'violence', 'world/life', 'night/time','shake the audience','family/gospel', 'romantic', 'communication','obscene', 'music', 'movement/places', 'light/visual perceptions','family/spiritual', 'like/girls', 'sadness', 'feelings', 'danceability','loudness', 'acousticness', 'instrumentalness', 'valence', 'energy']      \n\n\nfrom torch.utils.data import Dataset, DataLoader\n\nclass TextDataFromDF(Dataset):\n    def __init__(self, df):\n        self.df = df\n    \n    def __getitem__(self, index):\n        return self.df.iloc[index, 1], self.df.iloc[index, 0]\n\n    def __len__(self):\n        return len(self.df)\n\n\nimport torch\nimport pandas as pd\n\nimport numpy as np\n\n# for embedding visualization later\nimport plotly.express as px \nimport plotly.io as pio\n\n#---\n# for VSCode plotly rendering\npio.renderers.default = \"notebook\"\n#---\n\n# for appearance\npio.templates.default = \"plotly_white\"\n\n# for train-test split\nfrom sklearn.model_selection import train_test_split\n\n# for suppressing bugged warnings from torchinfo\nimport warnings \nwarnings.filterwarnings(\"ignore\", category = UserWarning)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
  },
  {
    "objectID": "posts/logistic/logistic-regression.html#abstract",
    "href": "posts/logistic/logistic-regression.html#abstract",
    "title": "Implementing Logistic Regression",
    "section": "Abstract",
    "text": "Abstract\nIn this post I provide several experiments with logistic regression with differing parameters. Here is a link to my logistic.py file, including my implementation for logistic regression with Spicy Gradient Descent, which includes two learning rate parameters.\nThrough three experiments, I demonstrate the effects of varying parameters of the classification data and logistic model. The first experiment demonstrates Vanilla gradient descent with only one learning rate parameter, showing how the loss decreases monotonically over time. The second experiment adds a second learning rate, demonstrating the effects of Spicy Gradient Descent, and how the weight vector converges much more quickly than with Vanilla gradient descent. The final experiment demonstrates the effects of overfitting to the training data, causing poorer performance on the test data.\nFirst I will define a function that generates classification data to be used in the logistic model. The parameters describe the number of data points, the noise level (describing variation in the data), and the dimensions of the data matrix.\n\ndef classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    y = 1.0*y\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n    \n    return X, y"
  }
]